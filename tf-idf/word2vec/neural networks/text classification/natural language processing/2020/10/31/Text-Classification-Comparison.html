<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>A Comparison of TF-IDF, Word2Vec, and Transfer Learning for Text Classification | How To Speak Computer</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="A Comparison of TF-IDF, Word2Vec, and Transfer Learning for Text Classification" />
<meta name="author" content="David Byron" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Summary" />
<meta property="og:description" content="Summary" />
<link rel="canonical" href="https://davidbyron.info/blog/tf-idf/word2vec/neural%20networks/text%20classification/natural%20language%20processing/2020/10/31/Text-Classification-Comparison.html" />
<meta property="og:url" content="https://davidbyron.info/blog/tf-idf/word2vec/neural%20networks/text%20classification/natural%20language%20processing/2020/10/31/Text-Classification-Comparison.html" />
<meta property="og:site_name" content="How To Speak Computer" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-10-31T00:00:00-05:00" />
<script type="application/ld+json">
{"url":"https://davidbyron.info/blog/tf-idf/word2vec/neural%20networks/text%20classification/natural%20language%20processing/2020/10/31/Text-Classification-Comparison.html","@type":"BlogPosting","headline":"A Comparison of TF-IDF, Word2Vec, and Transfer Learning for Text Classification","dateModified":"2020-10-31T00:00:00-05:00","datePublished":"2020-10-31T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://davidbyron.info/blog/tf-idf/word2vec/neural%20networks/text%20classification/natural%20language%20processing/2020/10/31/Text-Classification-Comparison.html"},"author":{"@type":"Person","name":"David Byron"},"description":"Summary","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://davidbyron.info/blog/feed.xml" title="How To Speak Computer" /><link rel="shortcut icon" type="image/x-icon" href="/blog/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/blog/">How To Speak Computer</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog/search/">Search</a><a class="page-link" href="/blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">A Comparison of TF-IDF, Word2Vec, and Transfer Learning for Text Classification</h1><p class="page-description">Summary</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-10-31T00:00:00-05:00" itemprop="datePublished">
        Oct 31, 2020
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">David Byron</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      84 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/blog/categories/#tf-idf">tf-idf</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#word2vec">word2vec</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#neural networks">neural networks</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#text classification">text classification</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#natural language processing">natural language processing</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/davbyron/blog/tree/master/_notebooks/2020-10-31-Text-Classification-Comparison.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/blog/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/davbyron/blog/master?filepath=_notebooks%2F2020-10-31-Text-Classification-Comparison.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blog/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/davbyron/blog/blob/master/_notebooks/2020-10-31-Text-Classification-Comparison.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blog/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#Data-Analysis,-Augmentation,-and-Splitting">Data Analysis, Augmentation, and Splitting </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Light-Analysis">Light Analysis </a></li>
<li class="toc-entry toc-h3"><a href="#Data-Augmentation">Data Augmentation </a>
<ul>
<li class="toc-entry toc-h4"><a href="#Cleaning">Cleaning </a></li>
<li class="toc-entry toc-h4"><a href="#n-grams">n-grams </a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#Splitting">Splitting </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#TF-IDF">TF-IDF </a>
<ul>
<li class="toc-entry toc-h3"><a href="#TF-IDF-with-Unprocessed-Tweets">TF-IDF with Unprocessed Tweets </a></li>
<li class="toc-entry toc-h3"><a href="#TF-IDF-with-"Simple"-Tweets">TF-IDF with &quot;Simple&quot; Tweets </a></li>
<li class="toc-entry toc-h3"><a href="#TF-IDF-with-SpaCy-Tweets">TF-IDF with SpaCy Tweets </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Word2Vec">Word2Vec </a>
<ul>
<li class="toc-entry toc-h4"><a href="#Word2Vec-Preprocessing">Word2Vec Preprocessing </a></li>
<li class="toc-entry toc-h3"><a href="#Word2Vec-with-Unprocessed-Tweets">Word2Vec with Unprocessed Tweets </a></li>
<li class="toc-entry toc-h3"><a href="#Word2Vec-with-"Simple"-Tweets">Word2Vec with &quot;Simple&quot; Tweets </a></li>
<li class="toc-entry toc-h3"><a href="#Word2Vec-with-SpaCy-Tweets">Word2Vec with SpaCy Tweets </a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#Transfer-Learning-with-fastai">Transfer Learning with fastai </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Transfer-Learning-with-Unprocessed-Tweets">Transfer Learning with Unprocessed Tweets </a></li>
<li class="toc-entry toc-h3"><a href="#Transfer-Learning-with-"Simple"-Tweets">Transfer Learning with &quot;Simple&quot; Tweets </a></li>
<li class="toc-entry toc-h3"><a href="#Transfer-Learning-with-SpaCy-Tweets">Transfer Learning with SpaCy Tweets </a></li>
<li class="toc-entry toc-h2"><a href="#Conclusion">Conclusion </a></li>
</ul>
</li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-10-31-Text-Classification-Comparison.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Text Classification is the assignment of a particular label to a text with respect to its content. In modern Natural Language Processing (NLP), there are many different algorithms and techniques used to gain significant accuracy in text classification tasks.</p>
<p>In this notebook, we will cover three of the most popular methods for text classification: TF-IDF, Word2Vec, and transfer learning. For each of the three methods, we will also show their effectiveness based on the amount of preprocessing that is done to the text beforehand, leaving us with a total of nine measurements at the end.</p>
<p>We will see that transfer learning is by far the superior method for the task in terms of ease of use and accuracy.</p>
<p>The data that we will be using comes from <a href="https://www.kaggle.com/c/nlp-getting-started">Kaggle's "Real or Not? NLP with Disaster Tweets"</a> competition, where the user is tasked with predicting which tweets are about real disasters, and which ones are not.</p>
<p>In the competition, leaderboard position is based on the model's F1 score. Therefore, for clarity, we will provide both the accuracy and F1 score for each output below.</p>
<p>To begin, let's start with some data analysis and augmentation:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Data-Analysis,-Augmentation,-and-Splitting">
<a class="anchor" href="#Data-Analysis,-Augmentation,-and-Splitting" aria-hidden="true"><span class="octicon octicon-link"></span></a>Data Analysis, Augmentation, and Splitting<a class="anchor-link" href="#Data-Analysis,-Augmentation,-and-Splitting"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Light-Analysis">
<a class="anchor" href="#Light-Analysis" aria-hidden="true"><span class="octicon octicon-link"></span></a>Light Analysis<a class="anchor-link" href="#Light-Analysis"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>First, let's take a look at the training data we're given:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'train.csv'</span><span class="p">)</span>
<span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>keyword</th>
      <th>location</th>
      <th>text</th>
      <th>target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Our Deeds are the Reason of this #earthquake M...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Forest fire near La Ronge Sask. Canada</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>All residents asked to 'shelter in place' are ...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>6</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>13,000 people receive #wildfires evacuation or...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>7</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Just got sent this photo from Ruby #Alaska as ...</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To find out a bit more information about the data, we can use the <code>.info()</code> and <code>.nunique()</code> methods on our DataFrame:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 7613 entries, 0 to 7612
Data columns (total 5 columns):
 #   Column    Non-Null Count  Dtype 
---  ------    --------------  ----- 
 0   id        7613 non-null   int64 
 1   keyword   7552 non-null   object
 2   location  5080 non-null   object
 3   text      7613 non-null   object
 4   target    7613 non-null   int64 
dtypes: int64(2), object(3)
memory usage: 297.5+ KB
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>id          7613
keyword      221
location    3341
text        7503
target         2
dtype: int64</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Interesting! It looks like some of the tweets (110 of them, to be precise) are the same.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Data-Augmentation">
<a class="anchor" href="#Data-Augmentation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Data Augmentation<a class="anchor-link" href="#Data-Augmentation"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Cleaning">
<a class="anchor" href="#Cleaning" aria-hidden="true"><span class="octicon octicon-link"></span></a>Cleaning<a class="anchor-link" href="#Cleaning"> </a>
</h4>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">spacy</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As mentioned above, I will incorporate different methods of preprocessing to our data to see if such changes have a positive or negative effect on our evaluation metrics. The three differently processed data I'll be using are:</p>
<ol>
<li>Unprocessed - the data as it is given to us.</li>
<li>"Simply" cleaned - the data without any hashtags, @-symbols, website links, or punctuation.</li>
<li>SpaCy cleaned - the data lemmatized and without any stop words according to SpaCy's pretrained English language model (which we'll get to in a moment).</li>
</ol>
<p>The unprocessed data is already done for us in the <code>text</code> column of our DataFrame.</p>
<p>Moving on to the second preprocessing method, "simply" cleaned data. By "simply" I mean cleaned explicitly by me using <a href="https://docs.python.org/3/library/re.html">regular expressions</a> with prior assumptions about the data. For the data we're using here, we have a bunch of tweets. Thererfore, it makes sense to me to remove things like hashtags, @-symbols, and websites, since those don't intuitively seem like they contribute to a tweets disaster level (though this isn't necessarily true, just an assumption!).</p>
<p>To achieve this "simple" cleaning of the data, we can use the following three functions I've created:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">remove_at_hash</span><span class="p">(</span><span class="n">sent</span><span class="p">):</span>
    <span class="sd">""" Returns a string with @-symbols and hashtags removed. """</span>
    <span class="k">return</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">'@|#'</span><span class="p">,</span> <span class="sa">r</span><span class="s1">''</span><span class="p">,</span> <span class="n">sent</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>

<span class="k">def</span> <span class="nf">remove_sites</span><span class="p">(</span><span class="n">sent</span><span class="p">):</span>
    <span class="sd">""" Returns a string with any websites starting with 'http.' removed. """</span>
    <span class="k">return</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">'http.*'</span><span class="p">,</span> <span class="sa">r</span><span class="s1">''</span><span class="p">,</span> <span class="n">sent</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>

<span class="k">def</span> <span class="nf">remove_punct</span><span class="p">(</span><span class="n">sent</span><span class="p">):</span>
    <span class="sd">""" Returns a string with only English unicode word characters ([a-zA-Z0-9_]). """</span>
    <span class="k">return</span> <span class="s1">' '</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="sa">r</span><span class="s1">'\w+'</span><span class="p">,</span> <span class="n">sent</span><span class="o">.</span><span class="n">lower</span><span class="p">()))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we can create a new column in our <code>data</code> DataFrame that represents the "simply" cleaned tweets. I'll call this column <code>text_simple</code>.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data</span><span class="p">[</span><span class="s1">'text_simple'</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">'text'</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">remove_punct</span><span class="p">(</span><span class="n">remove_sites</span><span class="p">(</span><span class="n">remove_at_hash</span><span class="p">(</span><span class="n">x</span><span class="p">))))</span>
<span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>keyword</th>
      <th>location</th>
      <th>text</th>
      <th>target</th>
      <th>text_simple</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Our Deeds are the Reason of this #earthquake M...</td>
      <td>1</td>
      <td>our deeds are the reason of this earthquake ma...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Forest fire near La Ronge Sask. Canada</td>
      <td>1</td>
      <td>forest fire near la ronge sask canada</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>All residents asked to 'shelter in place' are ...</td>
      <td>1</td>
      <td>all residents asked to shelter in place are be...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>6</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>13,000 people receive #wildfires evacuation or...</td>
      <td>1</td>
      <td>13 000 people receive wildfires evacuation ord...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>7</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Just got sent this photo from Ruby #Alaska as ...</td>
      <td>1</td>
      <td>just got sent this photo from ruby alaska as s...</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Moving now to the last preprocessing method: SpaCy. <a href="https://spacy.io/">SpaCy</a> is a great, open-source software library for NLP. It includes varying, pretrained language models of a number of different sizes for a number of different langauges, allowing you to quickly perform routine NLP tasks. Here, we're going to use SpaCy to <a href="https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html">lemmatize</a> each tweet in the data and remove any <a href="https://en.wikipedia.org/wiki/Stop_word">stop words</a>.</p>
<p>Below, we need to first load in SpaCy's (full) English model (note that, for speed, I disable some features that we won't need here). Then, create a function that will give us a string lemmatized by SpaCy.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">nlp</span> <span class="o">=</span> <span class="n">spacy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">'en'</span><span class="p">,</span> <span class="n">disable</span><span class="o">=</span><span class="p">[</span><span class="s1">'ner'</span><span class="p">,</span> <span class="s1">'parser'</span><span class="p">])</span> <span class="c1"># disabling features we don't need, for speed</span>

<span class="k">def</span> <span class="nf">spacy_cleaning</span><span class="p">(</span><span class="n">doc</span><span class="p">):</span>
    <span class="sd">""" Returns a string that has been lemmatized and rid of stop words via SpaCy. """</span>
    <span class="n">doc</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">(</span><span class="n">doc</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
    <span class="n">text</span> <span class="o">=</span> <span class="p">[</span><span class="n">token</span><span class="o">.</span><span class="n">lemma_</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">doc</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">token</span><span class="o">.</span><span class="n">is_stop</span><span class="p">]</span>
    <span class="k">return</span> <span class="s1">' '</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Using our new function, we can again create a new column in our <code>data</code> DataFrame with the SpaCy-cleaned tweets. I'll call this column <code>text_spacy</code>.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data</span><span class="p">[</span><span class="s1">'text_spacy'</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">'text'</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">spacy_cleaning</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>keyword</th>
      <th>location</th>
      <th>text</th>
      <th>target</th>
      <th>text_simple</th>
      <th>text_spacy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Our Deeds are the Reason of this #earthquake M...</td>
      <td>1</td>
      <td>our deeds are the reason of this earthquake ma...</td>
      <td>deed reason # earthquake allah forgive</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Forest fire near La Ronge Sask. Canada</td>
      <td>1</td>
      <td>forest fire near la ronge sask canada</td>
      <td>forest fire near la ronge sask . canada</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>All residents asked to 'shelter in place' are ...</td>
      <td>1</td>
      <td>all residents asked to shelter in place are be...</td>
      <td>resident ask ' shelter place ' notify officer ...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>6</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>13,000 people receive #wildfires evacuation or...</td>
      <td>1</td>
      <td>13 000 people receive wildfires evacuation ord...</td>
      <td>13,000 people receive # wildfire evacuation or...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>7</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Just got sent this photo from Ruby #Alaska as ...</td>
      <td>1</td>
      <td>just got sent this photo from ruby alaska as s...</td>
      <td>get send photo ruby # alaska smoke # wildfire ...</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="n-grams">
<a class="anchor" href="#n-grams" aria-hidden="true"><span class="octicon octicon-link"></span></a>n-grams<a class="anchor-link" href="#n-grams"> </a>
</h4>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">gensim.models.phrases</span> <span class="kn">import</span> <span class="n">Phrases</span><span class="p">,</span> <span class="n">Phraser</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash flash-warn">
    <svg class="octicon octicon-zap" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M10.561 1.5a.016.016 0 00-.01.004L3.286 8.571A.25.25 0 003.462 9H6.75a.75.75 0 01.694 1.034l-1.713 4.188 6.982-6.793A.25.25 0 0012.538 7H9.25a.75.75 0 01-.683-1.06l2.008-4.418.003-.006a.02.02 0 00-.004-.009.02.02 0 00-.006-.006L10.56 1.5zM9.504.43a1.516 1.516 0 012.437 1.713L10.415 5.5h2.123c1.57 0 2.346 1.909 1.22 3.004l-7.34 7.142a1.25 1.25 0 01-.871.354h-.302a1.25 1.25 0 01-1.157-1.723L5.633 10.5H3.462c-1.57 0-2.346-1.909-1.22-3.004L9.503.429z"></path></svg>
    <strong>Important: </strong>I’ll only be applying what we learn in the n-gram section to the Word2Vec model. If you’d like to skip this section, and come back when you get to Word2Vec, feel free to do so.
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>An <a href="https://en.wikipedia.org/wiki/N-gram#:~:text=In%20the%20fields%20of%20computational,a%20text%20or%20speech%20corpus.">n-gram</a> is a contiguous sequence of <em>n</em> items from a given sample of text or speech. This turns out to be quite useful in NLP. Consider the phrase "New York Times". When all three words are together, the phrase is understood to mean the widely spread news source based in New York of the same moniker. However, if we split the words up (while maintaining original order), we get: "New York", "York Times", "New", "York", and "Times". These separate words and phrases can occur in many contexts other than those in which the full phrase "New York Times" is found, skewing the phrase's true meaning in the data. N-gram models allow us to concatenate these commonly occurring multi-word phrases in our data, allowing their true meaning to shine through.</p>
<p>Thankfully, we can use the <code>Phraser</code> and <code>Phrases</code> classes provided by <a href="https://radimrehurek.com/gensim/">gensim</a> in order to easily find n-grams in our data.</p>
<p>Let's start by getting trigrams found in the unprocessed data.</p>
<p>First, we extract the tweets and split them by whitespace characters.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">text</span> <span class="o">=</span> <span class="p">[</span><span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'\s+'</span><span class="p">,</span> <span class="n">tweet</span><span class="p">)</span> <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[</span><span class="s1">'text'</span><span class="p">]]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Then, we find bigrams throughout our data. Here we use a parameter of <code>min_count=30</code> for our <code>Phrases</code> class. This ensures that only bigrams that occur more than 30 times in the data are found. Many combinations of words occur side by side only a few times, and don't contribute much additional knowledge to our model, so this is important.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">bigram_phrases</span> <span class="o">=</span> <span class="n">Phrases</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">min_count</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
<span class="n">bigram</span> <span class="o">=</span> <span class="n">Phraser</span><span class="p">(</span><span class="n">bigram_phrases</span><span class="p">)</span>
<span class="n">bigram_text</span> <span class="o">=</span> <span class="n">bigram</span><span class="p">[</span><span class="n">text</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next, we can use the bigrams we just made to search for trigrams in the exact same way.
</p>
<div class="flash">
    <svg class="octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>This is repeatable! Keep going to find n-grams of size 5 if you wanted!
</div>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">trigram_phrases</span> <span class="o">=</span> <span class="n">Phrases</span><span class="p">(</span><span class="n">bigram_text</span><span class="p">,</span> <span class="n">min_count</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
<span class="n">trigram</span> <span class="o">=</span> <span class="n">Phraser</span><span class="p">(</span><span class="n">trigram_phrases</span><span class="p">)</span>
<span class="n">trigram_text</span> <span class="o">=</span> <span class="n">trigram</span><span class="p">[</span><span class="n">bigram_text</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>That's it! Now we can pop this list back into our <code>data</code> DataFrame to be used later.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data</span><span class="p">[</span><span class="s1">'text_trigram'</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s1">' '</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tweet</span><span class="p">)</span> <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="n">trigram_text</span><span class="p">]</span>
<span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>keyword</th>
      <th>location</th>
      <th>text</th>
      <th>target</th>
      <th>text_simple</th>
      <th>text_spacy</th>
      <th>text_trigram</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Our Deeds are the Reason of this #earthquake M...</td>
      <td>1</td>
      <td>our deeds are the reason of this earthquake ma...</td>
      <td>deed reason # earthquake allah forgive</td>
      <td>Our Deeds are the Reason of this #earthquake M...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Forest fire near La Ronge Sask. Canada</td>
      <td>1</td>
      <td>forest fire near la ronge sask canada</td>
      <td>forest fire near la ronge sask . canada</td>
      <td>Forest fire near La Ronge Sask. Canada</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>All residents asked to 'shelter in place' are ...</td>
      <td>1</td>
      <td>all residents asked to shelter in place are be...</td>
      <td>resident ask ' shelter place ' notify officer ...</td>
      <td>All residents asked to 'shelter in place' are ...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>6</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>13,000 people receive #wildfires evacuation or...</td>
      <td>1</td>
      <td>13 000 people receive wildfires evacuation ord...</td>
      <td>13,000 people receive # wildfire evacuation or...</td>
      <td>13,000 people receive #wildfires evacuation or...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>7</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Just got sent this photo from Ruby #Alaska as ...</td>
      <td>1</td>
      <td>just got sent this photo from ruby alaska as s...</td>
      <td>get send photo ruby # alaska smoke # wildfire ...</td>
      <td>Just got sent this photo from Ruby #Alaska as ...</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Great work! Now let's do the same for the <code>text_simple</code> and <code>text_spacy</code> columns.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">text_simple</span> <span class="o">=</span> <span class="p">[</span><span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'\s+'</span><span class="p">,</span> <span class="n">tweet</span><span class="p">)</span> <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[</span><span class="s1">'text_simple'</span><span class="p">]]</span>

<span class="n">bigram_phrases</span> <span class="o">=</span> <span class="n">Phrases</span><span class="p">(</span><span class="n">text_simple</span><span class="p">,</span> <span class="n">min_count</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
<span class="n">bigram</span> <span class="o">=</span> <span class="n">Phraser</span><span class="p">(</span><span class="n">bigram_phrases</span><span class="p">)</span>
<span class="n">bigram_text_simple</span> <span class="o">=</span> <span class="n">bigram</span><span class="p">[</span><span class="n">text_simple</span><span class="p">]</span>

<span class="n">trigram_phrases</span> <span class="o">=</span> <span class="n">Phrases</span><span class="p">(</span><span class="n">bigram_text_simple</span><span class="p">,</span> <span class="n">min_count</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
<span class="n">trigram</span> <span class="o">=</span> <span class="n">Phraser</span><span class="p">(</span><span class="n">trigram_phrases</span><span class="p">)</span>
<span class="n">trigram_text_simple</span> <span class="o">=</span> <span class="n">trigram</span><span class="p">[</span><span class="n">bigram_text_simple</span><span class="p">]</span>

<span class="n">data</span><span class="p">[</span><span class="s1">'text_trigram_simple'</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s1">' '</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tweet</span><span class="p">)</span> <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="n">trigram_text_simple</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">text_spacy</span> <span class="o">=</span> <span class="p">[</span><span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'\s+'</span><span class="p">,</span> <span class="n">tweet</span><span class="p">)</span> <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[</span><span class="s1">'text_spacy'</span><span class="p">]]</span>

<span class="n">bigram_phrases</span> <span class="o">=</span> <span class="n">Phrases</span><span class="p">(</span><span class="n">text_spacy</span><span class="p">,</span> <span class="n">min_count</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
<span class="n">bigram</span> <span class="o">=</span> <span class="n">Phraser</span><span class="p">(</span><span class="n">bigram_phrases</span><span class="p">)</span>
<span class="n">bigram_text_spacy</span> <span class="o">=</span> <span class="n">bigram</span><span class="p">[</span><span class="n">text_spacy</span><span class="p">]</span>

<span class="n">trigram_phrases</span> <span class="o">=</span> <span class="n">Phrases</span><span class="p">(</span><span class="n">bigram_text_spacy</span><span class="p">,</span> <span class="n">min_count</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
<span class="n">trigram</span> <span class="o">=</span> <span class="n">Phraser</span><span class="p">(</span><span class="n">trigram_phrases</span><span class="p">)</span>
<span class="n">trigram_text_spacy</span> <span class="o">=</span> <span class="n">trigram</span><span class="p">[</span><span class="n">bigram_text_spacy</span><span class="p">]</span>

<span class="n">data</span><span class="p">[</span><span class="s1">'text_trigram_spacy'</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s1">' '</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tweet</span><span class="p">)</span> <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="n">trigram_text_spacy</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>keyword</th>
      <th>location</th>
      <th>text</th>
      <th>target</th>
      <th>text_simple</th>
      <th>text_spacy</th>
      <th>text_trigram</th>
      <th>text_trigram_simple</th>
      <th>text_trigram_spacy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Our Deeds are the Reason of this #earthquake M...</td>
      <td>1</td>
      <td>our deeds are the reason of this earthquake ma...</td>
      <td>deed reason # earthquake allah forgive</td>
      <td>Our Deeds are the Reason of this #earthquake M...</td>
      <td>our deeds are the reason of this earthquake ma...</td>
      <td>deed reason # earthquake allah forgive</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Forest fire near La Ronge Sask. Canada</td>
      <td>1</td>
      <td>forest fire near la ronge sask canada</td>
      <td>forest fire near la ronge sask . canada</td>
      <td>Forest fire near La Ronge Sask. Canada</td>
      <td>forest fire near la ronge sask canada</td>
      <td>forest fire near la ronge sask . canada</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>All residents asked to 'shelter in place' are ...</td>
      <td>1</td>
      <td>all residents asked to shelter in place are be...</td>
      <td>resident ask ' shelter place ' notify officer ...</td>
      <td>All residents asked to 'shelter in place' are ...</td>
      <td>all residents asked to shelter in place are be...</td>
      <td>resident ask ' shelter place ' notify officer ...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>6</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>13,000 people receive #wildfires evacuation or...</td>
      <td>1</td>
      <td>13 000 people receive wildfires evacuation ord...</td>
      <td>13,000 people receive # wildfire evacuation or...</td>
      <td>13,000 people receive #wildfires evacuation or...</td>
      <td>13 000 people receive wildfires evacuation ord...</td>
      <td>13,000 people receive # wildfire evacuation or...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>7</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Just got sent this photo from Ruby #Alaska as ...</td>
      <td>1</td>
      <td>just got sent this photo from ruby alaska as s...</td>
      <td>get send photo ruby # alaska smoke # wildfire ...</td>
      <td>Just got sent this photo from Ruby #Alaska as ...</td>
      <td>just got sent this photo from ruby alaska as s...</td>
      <td>get send photo ruby # alaska smoke # wildfire ...</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Fantastic! We've found all of the trigrams and bigrams in each of our three datasets that occur more than 30 times. This data will prove to be very useful when we reach Word2Vec.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now that we've got the three separately preprocessed sets of tweets in neat columns in our dataset, it's time to split our data into training and validation data and begin our testing!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Splitting">
<a class="anchor" href="#Splitting" aria-hidden="true"><span class="octicon octicon-link"></span></a>Splitting<a class="anchor-link" href="#Splitting"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In order to properly test our data, we'll need to split it into training and validation sets. To do this, we simply pass our <code>data</code> DataFrame to sklearn's <code>train_test_split</code>. We reset the index of each newly-created DataFrame to avoid complications with indexing later on. Then, check the shapes to make everything adds up.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train</span><span class="p">,</span> <span class="n">valid</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">train</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
<span class="n">valid</span> <span class="o">=</span> <span class="n">valid</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>

<span class="n">train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">valid</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>((5709, 11), (1904, 11), (7613, 10))</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Things are looking good! One last preprocessing step is in order, and that is dividing our newly-created <code>train</code> data by their target labels, thereby giving us two new DataFrames representing disaster tweets and non-disaster tweets.</p>
<p>When we call <code>.nunique()</code> on both <code>disasters</code> and <code>not_disasters</code>, we can see that the unique number of <code>target</code>s in each DataFrame is 1, indicating we split the data properly.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">disasters</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="n">train</span><span class="p">[</span><span class="s1">'target'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
<span class="n">not_disasters</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="n">train</span><span class="p">[</span><span class="s1">'target'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>

<span class="n">disasters</span><span class="o">.</span><span class="n">nunique</span><span class="p">(),</span> <span class="n">not_disasters</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(level_0                2484
 index                  2484
 id                     2484
 keyword                 219
 location               1201
 text                   2440
 target                    1
 text_simple            2181
 text_spacy             2439
 text_trigram           2439
 text_trigram_simple    2181
 text_trigram_spacy     2438
 dtype: int64,
 level_0                3225
 index                  3225
 id                     3225
 keyword                 216
 location               1657
 text                   3210
 target                    1
 text_simple            3047
 text_spacy             3209
 text_trigram           3210
 text_trigram_simple    3047
 text_trigram_spacy     3209
 dtype: int64)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Awesome! We're all set and we can begin to train our models.</p>
<p>Let's start with TF-IDF.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="TF-IDF">
<a class="anchor" href="#TF-IDF" aria-hidden="true"><span class="octicon octicon-link"></span></a>TF-IDF<a class="anchor-link" href="#TF-IDF"> </a>
</h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>
<span class="kn">from</span> <span class="nn">gensim.corpora</span> <span class="kn">import</span> <span class="n">Dictionary</span>
<span class="kn">from</span> <span class="nn">gensim.models</span> <span class="kn">import</span> <span class="n">TfidfModel</span>
<span class="kn">from</span> <span class="nn">gensim.similarities</span> <span class="kn">import</span> <span class="n">MatrixSimilarity</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">f1_score</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>TF-IDF is an incredible, straightforward way to analyze document similarity. It involves no fancy machine learning, just the term frequency across documents! For this reason, we will begin with trying to use TF-IDF to determine if a tweet is about a disaster or not.</p>
<p>From <a href="http://www.tfidf.com/">tfidf.com</a>:</p>
<blockquote>
<p>Tf-idf stands for <em>term frequency-inverse document frequency</em>, and the tf-idf weight is a weight often used in information retrieval and text mining. This weight is a statistical measure used to evaluate how important a word is to a document in a collection or corpus. The importance increases proportionally to the number of times a word appears in the document but is offset by the frequency of the word in the corpus.</p>
</blockquote>
<p>You can learn more about the mathematical foundations of TF-IDF <a href="https://rare-technologies.com/pivoted-document-length-normalisation/">here</a>.
We'll start by analyzing the unprocessed tweets.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="TF-IDF-with-Unprocessed-Tweets">
<a class="anchor" href="#TF-IDF-with-Unprocessed-Tweets" aria-hidden="true"><span class="octicon octicon-link"></span></a>TF-IDF with Unprocessed Tweets<a class="anchor-link" href="#TF-IDF-with-Unprocessed-Tweets"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In order to calculate the similarity between two tweets (namely, a tweet in the validation set with a tweet in the training set) without having to do all the math out ourselves, we'll use <a href="https://radimrehurek.com/gensim/">gensim</a>, a free Python library that provides a lot of great NLP functionality.</p>
<p>Gensim requires a list of <em>texts</em> in a list of <em>documents</em>. For us, that's a list of <em>words in a tweet</em> in a list of <em>tweets</em>. So let's make that now.
</p>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>We’re using the unprocessed tweets in the <code>data[&amp;#8217;text&amp;#8217;]</code> column this time around. We’ll be using the other two preprocessed tweets in a bit!
</div>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">disaster_tweets</span> <span class="o">=</span> <span class="n">disasters</span><span class="p">[</span><span class="s1">'text'</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">not_disaster_tweets</span> <span class="o">=</span> <span class="n">not_disasters</span><span class="p">[</span><span class="s1">'text'</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

<span class="n">disaster_tweets_split</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tweet</span><span class="o">.</span><span class="n">split</span><span class="p">()]</span>
    <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="n">disaster_tweets</span>
<span class="p">]</span>
<span class="n">not_disaster_tweets_split</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tweet</span><span class="o">.</span><span class="n">split</span><span class="p">()]</span>
    <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="n">not_disaster_tweets</span>
<span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Thinking about a TF-IDF model, words that only occur once throughout the entire corpus will not provide any noteworthy advantage to the model. Therefore, in the next step, we remove words that only occur once from <code>disaster_tweets_split</code> and <code>not_disaster_tweets</code> split.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">disaster_tweets_word_frequency</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="n">disaster_tweets_split</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tweet</span><span class="p">:</span>
        <span class="n">disaster_tweets_word_frequency</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
        
<span class="n">not_disaster_tweets_word_frequency</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="n">not_disaster_tweets_split</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tweet</span><span class="p">:</span>
        <span class="n">not_disaster_tweets_word_frequency</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="n">disaster_tweets_split</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tweet</span> <span class="k">if</span> <span class="n">disaster_tweets_word_frequency</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="n">disaster_tweets_split</span>
<span class="p">]</span>

<span class="n">not_disaster_tweets_split</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tweet</span> <span class="k">if</span> <span class="n">not_disaster_tweets_word_frequency</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="n">not_disaster_tweets_split</span>
<span class="p">]</span>

<span class="c1"># NOTE -----&gt; Some of these tweets are now empty, it's probably fine to remove them, right?</span>
<span class="c1">#             Because TFIDF doesn't rely on labels in the OG table?</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next, we create a Dictionary object with gensim, which is a mapping between words and their integer ids. With this Dictionary object we can create a "corpus" for disaster tweets and non-disaster tweets by converting each document (i.e., tweet) in each set to a Bag of Words format (that is, a list of <code>(token_id, token_count)</code> tuples).</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">disaster_tweets_dct</span> <span class="o">=</span> <span class="n">Dictionary</span><span class="p">(</span><span class="n">disaster_tweets_split</span><span class="p">)</span>
<span class="n">not_disaster_tweets_dct</span> <span class="o">=</span> <span class="n">Dictionary</span><span class="p">(</span><span class="n">not_disaster_tweets_split</span><span class="p">)</span>

<span class="n">disaster_tweets_corpus</span> <span class="o">=</span> <span class="p">[</span><span class="n">disaster_tweets_dct</span><span class="o">.</span><span class="n">doc2bow</span><span class="p">(</span><span class="n">tweet</span><span class="p">)</span> <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="n">disaster_tweets_split</span><span class="p">]</span>
<span class="n">not_disaster_tweets_corpus</span> <span class="o">=</span> <span class="p">[</span><span class="n">not_disaster_tweets_dct</span><span class="o">.</span><span class="n">doc2bow</span><span class="p">(</span><span class="n">tweet</span><span class="p">)</span> <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="n">not_disaster_tweets_split</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Fit TF-IDF models for our two sets of tweets.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">disaster_tweets_tfidf</span> <span class="o">=</span> <span class="n">TfidfModel</span><span class="p">(</span><span class="n">disaster_tweets_corpus</span><span class="p">)</span>
<span class="n">not_disaster_tweets_tfidf</span> <span class="o">=</span> <span class="n">TfidfModel</span><span class="p">(</span><span class="n">not_disaster_tweets_corpus</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Apply the models to our corpora to get vectors for each tweet.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">disaster_tweets_tfidf_vectors</span> <span class="o">=</span> <span class="n">disaster_tweets_tfidf</span><span class="p">[</span><span class="n">disaster_tweets_corpus</span><span class="p">]</span>
<span class="n">not_disaster_tweets_tfidf_vectors</span> <span class="o">=</span> <span class="n">not_disaster_tweets_tfidf</span><span class="p">[</span><span class="n">not_disaster_tweets_corpus</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Create variable which we can index into using another vector to compute similarity.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">disaster_tweets_similarity</span> <span class="o">=</span> <span class="n">MatrixSimilarity</span><span class="p">(</span><span class="n">disaster_tweets_tfidf_vectors</span><span class="p">)</span>
<span class="n">not_disaster_tweets_similarity</span> <span class="o">=</span> <span class="n">MatrixSimilarity</span><span class="p">(</span><span class="n">not_disaster_tweets_tfidf_vectors</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we can compare each tweet in the validation set to each set of tweets (disaster and non-disaster) in the training set. Whichever set contains a greater number of "similar enough" tweets (to be determined by a threshold) determines how the validation tweet will be labeled.</p>
<p>First, configure the validation tweets in the same way that we did for the training tweets:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">valid_tweets</span> <span class="o">=</span> <span class="n">valid</span><span class="p">[</span><span class="s1">'text'</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

<span class="n">valid_tweets_split</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tweet</span><span class="o">.</span><span class="n">split</span><span class="p">()]</span>
    <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="n">valid_tweets</span>
<span class="p">]</span>

<span class="n">valid_tweets_word_frequency</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="n">valid_tweets_split</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tweet</span><span class="p">:</span>
        <span class="n">valid_tweets_word_frequency</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
    
<span class="n">valid_tweets_split</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tweet</span> <span class="k">if</span> <span class="n">valid_tweets_word_frequency</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="n">valid_tweets_split</span>
<span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We now have all the information we need to make our predictions! We can store our predictions in the <code>valid</code> DataFrame. This will make for easier access when comparing target to prediction.</p>
<p>To do that, we need to initialize a new column in the DataFrame, let's call it <code>prediction</code>:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">valid</span><span class="p">[</span><span class="s1">'prediction'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">valid</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">'int'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In order to make predictions using the model we just created, we have to compare each tweet in the validation data with each tweet in both the <code>disasters</code> DataFrame and the <code>not_disasters</code> DataFrame.</p>
<p>Therefore, for each tweet, we:</p>
<ol>
<li>Turn it into a BoW according to each set of tweets' Dictionary object.</li>
<li>Get a vector for it using each set's TF-IDF model.</li>
<li>Compare it's vector with each set's full set of tweets using the MatrixSimilarity object we created earleir.</li>
<li>Tally up the total number of disaster and non-disaster tweets whose cosine similarity is greater than 0.1.</li>
<li>If the disaster tally is greater than the non-disaster tally, we change the value of the prediction column for this tweet in the <code>valid</code> DataFrame to 1 (otherwise, it stays 0, indicating a non-disastrous guess).</li>
</ol>
<p>This is exemplefied below:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">valid</span><span class="p">)):</span>
    <span class="n">tweet</span> <span class="o">=</span> <span class="n">valid_tweets_split</span><span class="p">[</span><span class="n">row</span><span class="p">]</span>
    
    <span class="n">tweet_bow_with_disasters_dct</span> <span class="o">=</span> <span class="n">disaster_tweets_dct</span><span class="o">.</span><span class="n">doc2bow</span><span class="p">(</span><span class="n">tweet</span><span class="p">)</span>
    <span class="n">tweet_bow_with_not_disasters_dct</span> <span class="o">=</span> <span class="n">not_disaster_tweets_dct</span><span class="o">.</span><span class="n">doc2bow</span><span class="p">(</span><span class="n">tweet</span><span class="p">)</span>
    
    <span class="n">tweet_tfidf_vector_with_disasters_tfidf</span> <span class="o">=</span> <span class="n">disaster_tweets_tfidf</span><span class="p">[</span><span class="n">tweet_bow_with_disasters_dct</span><span class="p">]</span>
    <span class="n">tweet_tfidf_vector_with_not_disasters_tfidf</span> <span class="o">=</span> <span class="n">not_disaster_tweets_tfidf</span><span class="p">[</span><span class="n">tweet_bow_with_not_disasters_dct</span><span class="p">]</span>
    
    <span class="n">disaster_similarity_vector</span> <span class="o">=</span> <span class="n">disaster_tweets_similarity</span><span class="p">[</span><span class="n">tweet_tfidf_vector_with_disasters_tfidf</span><span class="p">]</span>
    <span class="n">not_disaster_similarity_vector</span> <span class="o">=</span> <span class="n">not_disaster_tweets_similarity</span><span class="p">[</span><span class="n">tweet_tfidf_vector_with_not_disasters_tfidf</span><span class="p">]</span>
    
    <span class="n">disaster_tally</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">disaster_similarity_vector</span> <span class="o">&gt;</span> <span class="mf">0.1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size</span> <span class="c1"># np.where() returns a tuple, so we have to index into [0] to get what we want</span>
    <span class="n">not_disaster_tally</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">not_disaster_similarity_vector</span> <span class="o">&gt;</span> <span class="mf">0.1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size</span>
    
    <span class="k">if</span> <span class="n">disaster_tally</span> <span class="o">&gt;</span> <span class="n">not_disaster_tally</span><span class="p">:</span>
        <span class="n">valid</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">row</span><span class="p">,</span> <span class="s1">'prediction'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If all went well, we should be able to see our predictions in the <code>valid</code> DataFrame...</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">valid</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>index</th>
      <th>id</th>
      <th>keyword</th>
      <th>location</th>
      <th>text</th>
      <th>target</th>
      <th>text_simple</th>
      <th>text_spacy</th>
      <th>text_trigram</th>
      <th>text_trigram_simple</th>
      <th>text_trigram_spacy</th>
      <th>prediction</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5830</td>
      <td>8329</td>
      <td>rubble</td>
      <td>West Africa</td>
      <td>#TNN: China's Stock Market Crash: Are There Ge...</td>
      <td>1</td>
      <td>tnn china s stock market crash are there gems ...</td>
      <td># tnn : china stock market crash : gem rubble ...</td>
      <td>#TNN: China's Stock Market Crash: Are There Ge...</td>
      <td>tnn china s stock market crash are there gems ...</td>
      <td># tnn : china stock market crash : gem rubble ...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2548</td>
      <td>3656</td>
      <td>destroy</td>
      <td>Honduras</td>
      <td>Black Ops 3 SEARCH AND DESTROY GAMEPLAY! (Hunt...</td>
      <td>0</td>
      <td>black ops 3 search and destroy gameplay hunted...</td>
      <td>black ops 3 search destroy gameplay ! ( hunt s...</td>
      <td>Black Ops 3 SEARCH AND DESTROY GAMEPLAY! (Hunt...</td>
      <td>black ops 3 search and destroy gameplay hunted...</td>
      <td>black ops 3 search destroy gameplay ! ( hunt s...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2644</td>
      <td>3796</td>
      <td>destruction</td>
      <td>NaN</td>
      <td>So you have a new weapon that can cause un-ima...</td>
      <td>1</td>
      <td>so you have a new weapon that can cause un ima...</td>
      <td>new weapon cause un - imaginable destruction .</td>
      <td>So you have a new weapon that can cause un-ima...</td>
      <td>so you have a new weapon that can cause un ima...</td>
      <td>new weapon cause un - imaginable destruction .</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>6078</td>
      <td>8684</td>
      <td>sinkhole</td>
      <td>Haddonfield, NJ</td>
      <td>Georgia sinkhole closes road swallows whole po...</td>
      <td>1</td>
      <td>georgia sinkhole closes road swallows whole pond</td>
      <td>georgia sinkhole close road swallow pond http:...</td>
      <td>Georgia sinkhole closes road swallows whole po...</td>
      <td>georgia sinkhole closes road swallows whole pond</td>
      <td>georgia sinkhole close road swallow pond http:...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>6531</td>
      <td>9342</td>
      <td>survived</td>
      <td>London</td>
      <td>Survived another tube strike with the last per...</td>
      <td>0</td>
      <td>survived another tube strike with the last per...</td>
      <td>survive tube strike person office reach home ....</td>
      <td>Survived another tube strike with the last per...</td>
      <td>survived another tube strike with the last per...</td>
      <td>survive tube strike person office reach home ....</td>
      <td>1</td>
    </tr>
    <tr>
      <th>5</th>
      <td>7168</td>
      <td>10272</td>
      <td>war%20zone</td>
      <td>We're All Mad Here</td>
      <td>Packing for CT aka my room looks like a war zone</td>
      <td>0</td>
      <td>packing for ct aka my room looks like a war zone</td>
      <td>pack ct aka room look like war zone</td>
      <td>Packing for CT aka my room looks like a war zone</td>
      <td>packing for ct aka my room looks_like a war zone</td>
      <td>pack ct aka room look_like war zone</td>
      <td>1</td>
    </tr>
    <tr>
      <th>6</th>
      <td>4140</td>
      <td>5887</td>
      <td>harm</td>
      <td>NaN</td>
      <td>sticks and stones may break my bones\nbut word...</td>
      <td>0</td>
      <td>sticks and stones may break my bones but words...</td>
      <td>stick stone break bone \n word harm</td>
      <td>sticks and stones may break my bones but words...</td>
      <td>sticks and stones may break my bones but words...</td>
      <td>stick stone break bone word harm</td>
      <td>0</td>
    </tr>
    <tr>
      <th>7</th>
      <td>4999</td>
      <td>7131</td>
      <td>military</td>
      <td>Virginia, USA</td>
      <td>@TeamHendrick @TeamHendrick @RIRInsider Finger...</td>
      <td>0</td>
      <td>teamhendrick teamhendrick ririnsider fingers c...</td>
      <td>@teamhendrick @teamhendrick @ririnsid finger c...</td>
      <td>@TeamHendrick @TeamHendrick @RIRInsider Finger...</td>
      <td>teamhendrick teamhendrick ririnsider fingers c...</td>
      <td>@teamhendrick @teamhendrick @ririnsid finger c...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>8</th>
      <td>270</td>
      <td>393</td>
      <td>annihilation</td>
      <td>BIG D  HOUSTON/BOSTON/DENVER</td>
      <td>U.S National Park Services Tonto National Fore...</td>
      <td>0</td>
      <td>u s national park services tonto national fore...</td>
      <td>u.s national park services tonto national fore...</td>
      <td>U.S National Park Services Tonto National Fore...</td>
      <td>u_s national park services tonto national fore...</td>
      <td>u.s national park services tonto national fore...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>9</th>
      <td>3163</td>
      <td>4541</td>
      <td>emergency</td>
      <td>Renfrew, Scotland</td>
      <td>@batfanuk we enjoyed the show today. Great fun...</td>
      <td>0</td>
      <td>batfanuk we enjoyed the show today great fun t...</td>
      <td>@batfanuk enjoy today . great fun . emergency ...</td>
      <td>@batfanuk we enjoyed the show today. Great fun...</td>
      <td>batfanuk we enjoyed the show today great fun t...</td>
      <td>@batfanuk enjoy today . great fun . emergency ...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>10</th>
      <td>5775</td>
      <td>8242</td>
      <td>rioting</td>
      <td>hertfordshire.</td>
      <td>But the government will not care. Police will ...</td>
      <td>1</td>
      <td>but the government will not care police will s...</td>
      <td>government care . police stop rioting eventual...</td>
      <td>But the government will not care. Police will ...</td>
      <td>but the government will not care police will s...</td>
      <td>government care . police stop rioting eventual...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>11</th>
      <td>6850</td>
      <td>9818</td>
      <td>trauma</td>
      <td>NaN</td>
      <td>@crazyindapeg @VETS78734 completely understand...</td>
      <td>0</td>
      <td>crazyindapeg vets78734 completely understandab...</td>
      <td>@crazyindapeg @vets78734 completely understand...</td>
      <td>@crazyindapeg @VETS78734 completely understand...</td>
      <td>crazyindapeg vets78734 completely understandab...</td>
      <td>@crazyindapeg @vets78734 completely understand...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>12</th>
      <td>7241</td>
      <td>10369</td>
      <td>weapons</td>
      <td>NaN</td>
      <td>#bigbrother #ch4 The X-37b's big brother revea...</td>
      <td>0</td>
      <td>bigbrother ch4 the x 37b s big brother reveale...</td>
      <td># bigbrother # ch4 x-37b big brother reveal : ...</td>
      <td>#bigbrother #ch4 The X-37b's big brother revea...</td>
      <td>bigbrother ch4 the x 37b s big brother reveale...</td>
      <td># bigbrother # ch4 x-37b big brother reveal : ...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>13</th>
      <td>525</td>
      <td>759</td>
      <td>avalanche</td>
      <td>UK</td>
      <td>Musician Kalle Mattson Recreates 34 Classic Al...</td>
      <td>0</td>
      <td>musician kalle mattson recreates 34 classic al...</td>
      <td>musician kalle mattson recreate 34 classic alb...</td>
      <td>Musician Kalle Mattson Recreates 34 Classic Al...</td>
      <td>musician kalle mattson recreates 34 classic al...</td>
      <td>musician kalle mattson recreate 34 classic alb...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>14</th>
      <td>5015</td>
      <td>7154</td>
      <td>mudslide</td>
      <td>Wales</td>
      <td>Hope Dorett's 'mudslide' cake wins?? #GBBO</td>
      <td>0</td>
      <td>hope dorett s mudslide cake wins gbbo</td>
      <td>hope dorett ' mudslide ' cake win ? ? # gbbo</td>
      <td>Hope Dorett's 'mudslide' cake wins?? #GBBO</td>
      <td>hope dorett s mudslide cake wins gbbo</td>
      <td>hope dorett ' mudslide ' cake win ?_? # gbbo</td>
      <td>0</td>
    </tr>
    <tr>
      <th>15</th>
      <td>3639</td>
      <td>5188</td>
      <td>fatalities</td>
      <td>NaN</td>
      <td>Mortal Kombat X: All Fatalities On Meat Predat...</td>
      <td>0</td>
      <td>mortal kombat x all fatalities on meat predator</td>
      <td>mortal kombat x : fatality meat predator . \n ...</td>
      <td>Mortal Kombat X: All Fatalities On Meat Predat...</td>
      <td>mortal kombat x all fatalities on meat predator</td>
      <td>mortal kombat x : fatality meat predator . htt...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>16</th>
      <td>4264</td>
      <td>6058</td>
      <td>heat%20wave</td>
      <td>State College, PA</td>
      <td>Must Read Forecast! Longest Streak of Triple-D...</td>
      <td>1</td>
      <td>must read forecast longest streak of triple di...</td>
      <td>read forecast ! long streak triple - digit hea...</td>
      <td>Must Read Forecast! Longest Streak of Triple-D...</td>
      <td>must read forecast longest streak of triple di...</td>
      <td>read forecast ! long streak triple - digit hea...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>17</th>
      <td>3218</td>
      <td>4617</td>
      <td>emergency%20services</td>
      <td>Henderson, Nevada</td>
      <td>Apply now to work for Dignity Health as #RN #E...</td>
      <td>0</td>
      <td>apply now to work for dignity health as rn eme...</td>
      <td>apply work dignity health # rn # emergency ser...</td>
      <td>Apply now to work for Dignity Health as #RN #E...</td>
      <td>apply now to work for dignity health as rn eme...</td>
      <td>apply work dignity health # rn # emergency ser...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>18</th>
      <td>2227</td>
      <td>3185</td>
      <td>deluge</td>
      <td>NaN</td>
      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>
      <td>0</td>
      <td>the f amp ing things i do for gishwhes just go...</td>
      <td>f$&amp;amp;@ing thing # gishwhe get soak deluge go...</td>
      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>
      <td>the f amp ing things i do for gishwhes just go...</td>
      <td>f$&amp;amp;@ing thing # gishwhe get soak deluge go...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>19</th>
      <td>1163</td>
      <td>1675</td>
      <td>bridge%20collapse</td>
      <td>NaN</td>
      <td>Sioux City Fire Officials Believe Bridge Colla...</td>
      <td>1</td>
      <td>sioux city fire officials believe bridge colla...</td>
      <td>sioux city fire official believe bridge collap...</td>
      <td>Sioux City Fire Officials Believe Bridge Colla...</td>
      <td>sioux city fire officials believe bridge colla...</td>
      <td>sioux city fire official believe bridge collap...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>20</th>
      <td>4177</td>
      <td>5933</td>
      <td>harm</td>
      <td>Los Angeles, California</td>
      <td>Quality Metrics Penalties May Harm Patient Car...</td>
      <td>0</td>
      <td>quality metrics penalties may harm patient car...</td>
      <td>quality metric penalty harm patient care pcps ...</td>
      <td>Quality Metrics Penalties May Harm Patient Car...</td>
      <td>quality metrics penalties may harm patient car...</td>
      <td>quality metric penalty harm patient care pcps ...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>21</th>
      <td>2433</td>
      <td>3495</td>
      <td>derailed</td>
      <td>NYC</td>
      <td>Sad that biker beatdown derailed his pro-democ...</td>
      <td>1</td>
      <td>sad that biker beatdown derailed his pro democ...</td>
      <td>sad biker beatdown derail pro - democracy work...</td>
      <td>Sad that biker beatdown derailed his pro-democ...</td>
      <td>sad that biker beatdown derailed his pro democ...</td>
      <td>sad biker beatdown derail pro - democracy work...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>22</th>
      <td>938</td>
      <td>1356</td>
      <td>blown%20up</td>
      <td>kisumu</td>
      <td>LONER DIARIES.\n\nThe patterns  on the sand\nM...</td>
      <td>0</td>
      <td>loner diaries the patterns on the sand may hav...</td>
      <td>loner diary . \n\n pattern   sand \n blow away...</td>
      <td>LONER DIARIES. The patterns on the sand May ha...</td>
      <td>loner diaries the patterns on the sand may_hav...</td>
      <td>loner diary . pattern sand blow away . photo t...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>23</th>
      <td>1837</td>
      <td>2642</td>
      <td>crashed</td>
      <td>too far</td>
      <td>He was only .4 of a second faster than me and ...</td>
      <td>0</td>
      <td>he was only 4 of a second faster than me and i...</td>
      <td>.4 second fast overtook twice ( crash ) tru lu...</td>
      <td>He was only .4 of a second faster than me and ...</td>
      <td>he was only 4 of a second faster than me and i...</td>
      <td>.4 second fast overtook twice ( crash ) tru lu...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>24</th>
      <td>526</td>
      <td>761</td>
      <td>avalanche</td>
      <td>London, Kent &amp; SE England.</td>
      <td>Beautiful Sweet Avalanche Faith and Akito rose...</td>
      <td>0</td>
      <td>beautiful sweet avalanche faith and akito rose...</td>
      <td>beautiful sweet avalanche faith akito rose lot...</td>
      <td>Beautiful Sweet Avalanche Faith and Akito rose...</td>
      <td>beautiful sweet avalanche faith and akito rose...</td>
      <td>beautiful sweet avalanche faith akito rose lot...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>25</th>
      <td>3575</td>
      <td>5107</td>
      <td>famine</td>
      <td>Chatham, IL</td>
      <td>Images of Famine ÛÒ Hope In Christ - A blog o...</td>
      <td>1</td>
      <td>images of famine ûò hope in christ a blog on w...</td>
      <td>image famine ûò hope christ - blog happen for...</td>
      <td>Images of Famine ÛÒ Hope In Christ - A blog o...</td>
      <td>images of famine ûò hope in christ a blog on w...</td>
      <td>image famine ûò hope christ - blog happen for...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>26</th>
      <td>3546</td>
      <td>5069</td>
      <td>famine</td>
      <td>PanamÌÁ</td>
      <td>Top 3:\n* Turn on the Darkness\n* King Redeem ...</td>
      <td>0</td>
      <td>top 3 turn on the darkness king redeem queen s...</td>
      <td>3 : \n * turn darkness \n * king redeem - quee...</td>
      <td>Top 3: * Turn on the Darkness * King Redeem - ...</td>
      <td>top 3 turn on the darkness king redeem queen s...</td>
      <td>3 : * turn darkness * king redeem - queen sere...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>27</th>
      <td>6727</td>
      <td>9640</td>
      <td>thunderstorm</td>
      <td>NaN</td>
      <td>Falling asleep to the sounds to thousands of R...</td>
      <td>0</td>
      <td>falling asleep to the sounds to thousands of r...</td>
      <td>fall asleep sound thousand river plate fan sta...</td>
      <td>Falling asleep to the sounds to thousands of R...</td>
      <td>falling asleep to the sounds to thousands of r...</td>
      <td>fall asleep sound thousand river plate fan sta...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>28</th>
      <td>4123</td>
      <td>5861</td>
      <td>hailstorm</td>
      <td>NaN</td>
      <td>Summer heat drives bobcats to Calgary backyard...</td>
      <td>1</td>
      <td>summer heat drives bobcats to calgary backyards 3</td>
      <td>summer heat drive bobcat calgary backyard ~ 3 ...</td>
      <td>Summer heat drives bobcats to Calgary backyard...</td>
      <td>summer heat drives bobcats to calgary backyards 3</td>
      <td>summer heat drive bobcat calgary backyard ~ 3 ...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>29</th>
      <td>4992</td>
      <td>7122</td>
      <td>military</td>
      <td>NaN</td>
      <td>Online infantryman experimental military train...</td>
      <td>0</td>
      <td>online infantryman experimental military train...</td>
      <td>online infantryman experimental military train...</td>
      <td>Online infantryman experimental military train...</td>
      <td>online infantryman experimental military train...</td>
      <td>online infantryman experimental military train...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>30</th>
      <td>5685</td>
      <td>8112</td>
      <td>rescued</td>
      <td>NaN</td>
      <td>I liked a @YouTube video http://t.co/45TWHJ0l6...</td>
      <td>0</td>
      <td>i liked a youtube video</td>
      <td>like @youtube video http://t.co/45twhj0l6 m ro...</td>
      <td>I_liked_a_@YouTube video http://t.co/45TWHJ0l6...</td>
      <td>i_liked_a_youtube video</td>
      <td>like_@youtube_video http://t.co/45twhj0l6 m ro...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>31</th>
      <td>3450</td>
      <td>4934</td>
      <td>exploded</td>
      <td>USA</td>
      <td>If you told me ten years ago that I'd be seein...</td>
      <td>0</td>
      <td>if you told me ten years ago that i d be seein...</td>
      <td>tell year ago see anime big screen ... ... pro...</td>
      <td>If you told me ten years ago that I'd be seein...</td>
      <td>if_you told me ten years ago that i d be seein...</td>
      <td>tell year ago see anime big screen ... ... pro...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>32</th>
      <td>2045</td>
      <td>2935</td>
      <td>danger</td>
      <td>Atlanta Georgia</td>
      <td>@RemainOnTop #FETTILOOTCH IS #SLANGLUCCI OPPRE...</td>
      <td>0</td>
      <td>remainontop fettilootch is slanglucci oppressi...</td>
      <td>@remainontop # fettilootch # slanglucci oppres...</td>
      <td>@RemainOnTop #FETTILOOTCH IS #SLANGLUCCI OPPRE...</td>
      <td>remainontop fettilootch is slanglucci oppressi...</td>
      <td>@remainontop # fettilootch # slanglucci oppres...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>33</th>
      <td>436</td>
      <td>633</td>
      <td>arsonist</td>
      <td>snapchat // fvck_casper</td>
      <td>@local_arsonist I guess u can say that it's ju...</td>
      <td>0</td>
      <td>local_arsonist i guess u can say that it s jus...</td>
      <td>@local_arsonist guess u shit think</td>
      <td>@local_arsonist I guess u can say that it's ju...</td>
      <td>local_arsonist i guess u can say that it_s jus...</td>
      <td>@local_arsonist guess u shit think</td>
      <td>0</td>
    </tr>
    <tr>
      <th>34</th>
      <td>3515</td>
      <td>5025</td>
      <td>eyewitness</td>
      <td>NaN</td>
      <td>Interesting approach but doesn't replace Eyewi...</td>
      <td>1</td>
      <td>interesting approach but doesn t replace eyewi...</td>
      <td>interesting approach replace eyewitness video ...</td>
      <td>Interesting approach but doesn't replace Eyewi...</td>
      <td>interesting approach but doesn t replace eyewi...</td>
      <td>interesting approach replace eyewitness video ...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>35</th>
      <td>4419</td>
      <td>6282</td>
      <td>hijacking</td>
      <td>NaN</td>
      <td>Mom is hijacking my account to earn MCR STATUS...</td>
      <td>0</td>
      <td>mom is hijacking my account to earn mcr status...</td>
      <td>mom hijack account earn mcr status ! ! !   acc...</td>
      <td>Mom is hijacking my account to earn MCR STATUS...</td>
      <td>mom is hijacking my account to earn mcr status...</td>
      <td>mom hijack account earn mcr status !_!_! accou...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>36</th>
      <td>3945</td>
      <td>5609</td>
      <td>flood</td>
      <td>New York</td>
      <td>12' 72W CREE LED Work Light Bar Alloy Spot Flo...</td>
      <td>0</td>
      <td>12 72w cree led work light bar alloy spot floo...</td>
      <td>12 ' 72w cree lead work light bar alloy spot f...</td>
      <td>12' 72W CREE LED Work Light Bar Alloy Spot Flo...</td>
      <td>12 72w cree led work light bar alloy spot floo...</td>
      <td>12 ' 72w cree lead work light bar alloy spot f...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>37</th>
      <td>1142</td>
      <td>1646</td>
      <td>bombing</td>
      <td>NaN</td>
      <td>The cryptic words that guided pilots on the Hi...</td>
      <td>1</td>
      <td>the cryptic words that guided pilots on the hi...</td>
      <td>cryptic word guide pilot hiroshima bombing mis...</td>
      <td>The cryptic words that guided pilots on the Hi...</td>
      <td>the cryptic words that guided pilots on the hi...</td>
      <td>cryptic word guide pilot hiroshima bombing mis...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>38</th>
      <td>3401</td>
      <td>4869</td>
      <td>explode</td>
      <td>Williamsburg, VA</td>
      <td>Housing Starts Explode to NewåÊHeights http://...</td>
      <td>0</td>
      <td>housing starts explode to newåêheights</td>
      <td>housing start explode newåêheight http://t.co/...</td>
      <td>Housing Starts Explode to NewåÊHeights http://...</td>
      <td>housing starts explode to newåêheights</td>
      <td>housing start explode newåêheight http://t.co/...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>39</th>
      <td>1628</td>
      <td>2351</td>
      <td>collapse</td>
      <td>Worldwide.</td>
      <td>åÈMGN-AFRICAå¨ pin:263789F4 åÈ Correction: Ten...</td>
      <td>0</td>
      <td>åèmgn africaå pin 263789f4 åè correction tent ...</td>
      <td>åèmgn - africaå¨ pin:263789f4 åè correction : ...</td>
      <td>åÈMGN-AFRICAå¨ pin:263789F4 åÈ Correction: Ten...</td>
      <td>åèmgn africaå pin 263789f4 åè correction tent ...</td>
      <td>åèmgn - africaå¨ pin:263789f4 åè correction : ...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>40</th>
      <td>1131</td>
      <td>1631</td>
      <td>bombing</td>
      <td>NaN</td>
      <td>The United Kingdom and France are bombing Daes...</td>
      <td>1</td>
      <td>the united kingdom and france are bombing daes...</td>
      <td>united kingdom france bomb daesh syria - volta...</td>
      <td>The United Kingdom and France are bombing Daes...</td>
      <td>the united kingdom and france are bombing daes...</td>
      <td>united kingdom france bomb daesh syria - volta...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>41</th>
      <td>4869</td>
      <td>6932</td>
      <td>mass%20murderer</td>
      <td>NaN</td>
      <td>Another White mass murderer. Thank God I live ...</td>
      <td>1</td>
      <td>another white mass murderer thank god i live i...</td>
      <td>white mass murderer . thank god live californi...</td>
      <td>Another White mass murderer. Thank God I live ...</td>
      <td>another white mass_murderer thank god i live i...</td>
      <td>white mass murderer . thank god live californi...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>42</th>
      <td>1532</td>
      <td>2214</td>
      <td>chemical%20emergency</td>
      <td>London</td>
      <td>.@david_cameron Stop upsetting this bee! Liste...</td>
      <td>0</td>
      <td>david_cameron stop upsetting this bee listen t...</td>
      <td>.@david_cameron stop upset bee ! listen scienc...</td>
      <td>.@david_cameron Stop upsetting this bee! Liste...</td>
      <td>david_cameron stop upsetting this bee listen t...</td>
      <td>.@david_cameron stop upset bee ! listen scienc...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>43</th>
      <td>537</td>
      <td>782</td>
      <td>avalanche</td>
      <td>Buy Give Me My Money</td>
      <td>Great one time deal on all Avalanche music and...</td>
      <td>0</td>
      <td>great one time deal on all avalanche music and...</td>
      <td>great time deal avalanche music purchase neal ...</td>
      <td>Great one time deal on all Avalanche music and...</td>
      <td>great one time deal on all avalanche music and...</td>
      <td>great time deal avalanche music purchase neal ...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>44</th>
      <td>5164</td>
      <td>7365</td>
      <td>obliterate</td>
      <td>NEWCASTLE</td>
      <td>@SkyNews how is this scum still alive oblitera...</td>
      <td>0</td>
      <td>skynews how is this scum still alive obliterat...</td>
      <td>@skynews scum alive obliterate cancer</td>
      <td>@SkyNews how is this scum still alive oblitera...</td>
      <td>skynews how is this scum still alive obliterat...</td>
      <td>@skynews scum alive obliterate cancer</td>
      <td>0</td>
    </tr>
    <tr>
      <th>45</th>
      <td>1057</td>
      <td>1526</td>
      <td>body%20bags</td>
      <td>Speaking the Truth in Love</td>
      <td>Fairfax investigating firefighter over Faceboo...</td>
      <td>0</td>
      <td>fairfax investigating firefighter over faceboo...</td>
      <td>fairfax investigate firefighter facebook post ...</td>
      <td>Fairfax investigating firefighter over Faceboo...</td>
      <td>fairfax investigating firefighter over faceboo...</td>
      <td>fairfax investigate firefighter facebook post ...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>46</th>
      <td>3844</td>
      <td>5469</td>
      <td>flames</td>
      <td>Freeport Ny</td>
      <td>Just added some more fire to the flames for Sa...</td>
      <td>0</td>
      <td>just added some more fire to the flames for sa...</td>
      <td>add fire flame saturday ! rick wonder spin gue...</td>
      <td>Just added some more fire to the flames for Sa...</td>
      <td>just added some more fire to the flames for sa...</td>
      <td>add fire flame saturday ! rick wonder spin gue...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>47</th>
      <td>3471</td>
      <td>4966</td>
      <td>explosion</td>
      <td>NaN</td>
      <td>Report: Corey Brewer was drug tested after 51-...</td>
      <td>1</td>
      <td>report corey brewer was drug tested after 51 p...</td>
      <td>report : corey brewer drug test 51-point explo...</td>
      <td>Report: Corey Brewer was drug tested after 51-...</td>
      <td>report corey brewer was drug tested after 51 p...</td>
      <td>report : corey brewer drug test 51-point explo...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>48</th>
      <td>3383</td>
      <td>4845</td>
      <td>evacuation</td>
      <td>sydney, australia</td>
      <td>my school just put the evacuation alarms on ac...</td>
      <td>0</td>
      <td>my school just put the evacuation alarms on ac...</td>
      <td>school evacuation alarm accidently 2 different...</td>
      <td>my school just put the evacuation alarms on ac...</td>
      <td>my school just put the evacuation alarms on ac...</td>
      <td>school evacuation alarm accidently 2 different...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>49</th>
      <td>5624</td>
      <td>8023</td>
      <td>refugees</td>
      <td>EspaÌ±a</td>
      <td>@ViralSpell: 'Couple spend wedding day feeding...</td>
      <td>0</td>
      <td>viralspell couple spend wedding day feeding 40...</td>
      <td>@viralspell : ' couple spend wedding day feed ...</td>
      <td>@ViralSpell: 'Couple spend wedding day feeding...</td>
      <td>viralspell couple spend wedding day feeding 40...</td>
      <td>@viralspell : ' couple spend wedding day feed ...</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Look at that! Seems we've made some predictions! But how well did we do?</p>
<p>Let's take a look at both the accuracy and F1 score:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">valid</span><span class="p">[</span><span class="s1">'target'</span><span class="p">],</span> <span class="n">valid</span><span class="p">[</span><span class="s1">'prediction'</span><span class="p">])</span>
<span class="n">F1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">valid</span><span class="p">[</span><span class="s1">'target'</span><span class="p">],</span> <span class="n">valid</span><span class="p">[</span><span class="s1">'prediction'</span><span class="p">])</span>
<span class="n">accuracy</span><span class="p">,</span> <span class="n">F1</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(0.6207983193277311, 0.48428571428571426)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>62.08%</code> accuracy! That's not too shabby for just looking at word frequencies...</p>
<p>But what happens if we calculate tweet similarities using TF-IDF again, but this time using the preprocessed data that we prepared in the last section?</p>
<p>Let's start by seeing how our scores improve with the "simply" cleaned tweets.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id='TF-IDF-with-"Simple"-Tweets'>
<a class="anchor" href="#TF-IDF-with-" simple aria-hidden="true"><span class="octicon octicon-link"></span></a>TF-IDF with "Simple" Tweets<a class="anchor-link" href="#TF-IDF-with-%22Simple%22-Tweets"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Before we go any further, we'll need to get rid of the predictions we just made in <code>valid</code>.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">valid</span> <span class="o">=</span> <span class="n">valid</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">'prediction'</span><span class="p">])</span>
<span class="n">valid</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>index</th>
      <th>id</th>
      <th>keyword</th>
      <th>location</th>
      <th>text</th>
      <th>target</th>
      <th>text_simple</th>
      <th>text_spacy</th>
      <th>text_trigram</th>
      <th>text_trigram_simple</th>
      <th>text_trigram_spacy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5830</td>
      <td>8329</td>
      <td>rubble</td>
      <td>West Africa</td>
      <td>#TNN: China's Stock Market Crash: Are There Ge...</td>
      <td>1</td>
      <td>tnn china s stock market crash are there gems ...</td>
      <td># tnn : china stock market crash : gem rubble ...</td>
      <td>#TNN: China's Stock Market Crash: Are There Ge...</td>
      <td>tnn china s stock market crash are there gems ...</td>
      <td># tnn : china stock market crash : gem rubble ...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2548</td>
      <td>3656</td>
      <td>destroy</td>
      <td>Honduras</td>
      <td>Black Ops 3 SEARCH AND DESTROY GAMEPLAY! (Hunt...</td>
      <td>0</td>
      <td>black ops 3 search and destroy gameplay hunted...</td>
      <td>black ops 3 search destroy gameplay ! ( hunt s...</td>
      <td>Black Ops 3 SEARCH AND DESTROY GAMEPLAY! (Hunt...</td>
      <td>black ops 3 search and destroy gameplay hunted...</td>
      <td>black ops 3 search destroy gameplay ! ( hunt s...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2644</td>
      <td>3796</td>
      <td>destruction</td>
      <td>NaN</td>
      <td>So you have a new weapon that can cause un-ima...</td>
      <td>1</td>
      <td>so you have a new weapon that can cause un ima...</td>
      <td>new weapon cause un - imaginable destruction .</td>
      <td>So you have a new weapon that can cause un-ima...</td>
      <td>so you have a new weapon that can cause un ima...</td>
      <td>new weapon cause un - imaginable destruction .</td>
    </tr>
    <tr>
      <th>3</th>
      <td>6078</td>
      <td>8684</td>
      <td>sinkhole</td>
      <td>Haddonfield, NJ</td>
      <td>Georgia sinkhole closes road swallows whole po...</td>
      <td>1</td>
      <td>georgia sinkhole closes road swallows whole pond</td>
      <td>georgia sinkhole close road swallow pond http:...</td>
      <td>Georgia sinkhole closes road swallows whole po...</td>
      <td>georgia sinkhole closes road swallows whole pond</td>
      <td>georgia sinkhole close road swallow pond http:...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>6531</td>
      <td>9342</td>
      <td>survived</td>
      <td>London</td>
      <td>Survived another tube strike with the last per...</td>
      <td>0</td>
      <td>survived another tube strike with the last per...</td>
      <td>survive tube strike person office reach home ....</td>
      <td>Survived another tube strike with the last per...</td>
      <td>survived another tube strike with the last per...</td>
      <td>survive tube strike person office reach home ....</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The process this time around will, in fact, be exactly the same as last time! The only change we need to make is that we are indexing into the <code>text_simple</code> column in the <code>disaster_tweets</code> and <code>not_disaster_tweets</code> DataFrames.</p>
<p>Since the procedure is the same, let's skip to the metrics! (You can still expand the code below if you need a closer look.)</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">disaster_tweets</span> <span class="o">=</span> <span class="n">disasters</span><span class="p">[</span><span class="s1">'text_simple'</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">not_disaster_tweets</span> <span class="o">=</span> <span class="n">not_disasters</span><span class="p">[</span><span class="s1">'text_simple'</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

<span class="n">disaster_tweets_split</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tweet</span><span class="o">.</span><span class="n">split</span><span class="p">()]</span>
    <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="n">disaster_tweets</span>
<span class="p">]</span>
<span class="n">not_disaster_tweets_split</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tweet</span><span class="o">.</span><span class="n">split</span><span class="p">()]</span>
    <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="n">not_disaster_tweets</span>
<span class="p">]</span>

<span class="n">disaster_tweets_word_frequency</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="n">disaster_tweets_split</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tweet</span><span class="p">:</span>
        <span class="n">disaster_tweets_word_frequency</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
        
<span class="n">not_disaster_tweets_word_frequency</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="n">not_disaster_tweets_split</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tweet</span><span class="p">:</span>
        <span class="n">not_disaster_tweets_word_frequency</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="n">disaster_tweets_split</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tweet</span> <span class="k">if</span> <span class="n">disaster_tweets_word_frequency</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="n">disaster_tweets_split</span>
<span class="p">]</span>

<span class="n">not_disaster_tweets_split</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tweet</span> <span class="k">if</span> <span class="n">not_disaster_tweets_word_frequency</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="n">not_disaster_tweets_split</span>
<span class="p">]</span>

<span class="n">disaster_tweets_dct</span> <span class="o">=</span> <span class="n">Dictionary</span><span class="p">(</span><span class="n">disaster_tweets_split</span><span class="p">)</span>
<span class="n">not_disaster_tweets_dct</span> <span class="o">=</span> <span class="n">Dictionary</span><span class="p">(</span><span class="n">not_disaster_tweets_split</span><span class="p">)</span>

<span class="n">disaster_tweets_corpus</span> <span class="o">=</span> <span class="p">[</span><span class="n">disaster_tweets_dct</span><span class="o">.</span><span class="n">doc2bow</span><span class="p">(</span><span class="n">tweet</span><span class="p">)</span> <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="n">disaster_tweets_split</span><span class="p">]</span>
<span class="n">not_disaster_tweets_corpus</span> <span class="o">=</span> <span class="p">[</span><span class="n">not_disaster_tweets_dct</span><span class="o">.</span><span class="n">doc2bow</span><span class="p">(</span><span class="n">tweet</span><span class="p">)</span> <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="n">not_disaster_tweets_split</span><span class="p">]</span>

<span class="n">disaster_tweets_tfidf</span> <span class="o">=</span> <span class="n">TfidfModel</span><span class="p">(</span><span class="n">disaster_tweets_corpus</span><span class="p">)</span>
<span class="n">not_disaster_tweets_tfidf</span> <span class="o">=</span> <span class="n">TfidfModel</span><span class="p">(</span><span class="n">not_disaster_tweets_corpus</span><span class="p">)</span>

<span class="n">disaster_tweets_tfidf_vectors</span> <span class="o">=</span> <span class="n">disaster_tweets_tfidf</span><span class="p">[</span><span class="n">disaster_tweets_corpus</span><span class="p">]</span>
<span class="n">not_disaster_tweets_tfidf_vectors</span> <span class="o">=</span> <span class="n">not_disaster_tweets_tfidf</span><span class="p">[</span><span class="n">not_disaster_tweets_corpus</span><span class="p">]</span>

<span class="n">disaster_tweets_similarity</span> <span class="o">=</span> <span class="n">MatrixSimilarity</span><span class="p">(</span><span class="n">disaster_tweets_tfidf_vectors</span><span class="p">)</span>
<span class="n">not_disaster_tweets_similarity</span> <span class="o">=</span> <span class="n">MatrixSimilarity</span><span class="p">(</span><span class="n">not_disaster_tweets_tfidf_vectors</span><span class="p">)</span>

<span class="n">valid_tweets</span> <span class="o">=</span> <span class="n">valid</span><span class="p">[</span><span class="s1">'text_simple'</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

<span class="n">valid_tweets_split</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tweet</span><span class="o">.</span><span class="n">split</span><span class="p">()]</span>
    <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="n">valid_tweets</span>
<span class="p">]</span>

<span class="n">valid_tweets_word_frequency</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="n">valid_tweets_split</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tweet</span><span class="p">:</span>
        <span class="n">valid_tweets_word_frequency</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
    
<span class="n">valid_tweets_split</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tweet</span> <span class="k">if</span> <span class="n">valid_tweets_word_frequency</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="n">valid_tweets_split</span>
<span class="p">]</span>

<span class="n">valid</span><span class="p">[</span><span class="s1">'prediction'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">valid</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">'int'</span><span class="p">)</span>

<span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">valid</span><span class="p">)):</span>
    <span class="n">tweet</span> <span class="o">=</span> <span class="n">valid_tweets_split</span><span class="p">[</span><span class="n">row</span><span class="p">]</span>
    
    <span class="n">tweet_bow_with_disasters_dct</span> <span class="o">=</span> <span class="n">disaster_tweets_dct</span><span class="o">.</span><span class="n">doc2bow</span><span class="p">(</span><span class="n">tweet</span><span class="p">)</span>
    <span class="n">tweet_bow_with_not_disasters_dct</span> <span class="o">=</span> <span class="n">not_disaster_tweets_dct</span><span class="o">.</span><span class="n">doc2bow</span><span class="p">(</span><span class="n">tweet</span><span class="p">)</span>
    
    <span class="n">tweet_tfidf_vector_with_disasters_tfidf</span> <span class="o">=</span> <span class="n">disaster_tweets_tfidf</span><span class="p">[</span><span class="n">tweet_bow_with_disasters_dct</span><span class="p">]</span>
    <span class="n">tweet_tfidf_vector_with_not_disasters_tfidf</span> <span class="o">=</span> <span class="n">not_disaster_tweets_tfidf</span><span class="p">[</span><span class="n">tweet_bow_with_not_disasters_dct</span><span class="p">]</span>
    
    <span class="n">disaster_similarity_vector</span> <span class="o">=</span> <span class="n">disaster_tweets_similarity</span><span class="p">[</span><span class="n">tweet_tfidf_vector_with_disasters_tfidf</span><span class="p">]</span>
    <span class="n">not_disaster_similarity_vector</span> <span class="o">=</span> <span class="n">not_disaster_tweets_similarity</span><span class="p">[</span><span class="n">tweet_tfidf_vector_with_not_disasters_tfidf</span><span class="p">]</span>
    
    <span class="n">disaster_tally</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">disaster_similarity_vector</span> <span class="o">&gt;</span> <span class="mf">0.1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size</span> <span class="c1"># np.where() returns a tuple, so we have to index into [0] to get what we want</span>
    <span class="n">not_disaster_tally</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">not_disaster_similarity_vector</span> <span class="o">&gt;</span> <span class="mf">0.1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size</span>
    
    <span class="k">if</span> <span class="n">disaster_tally</span> <span class="o">&gt;</span> <span class="n">not_disaster_tally</span><span class="p">:</span>
        <span class="n">valid</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">row</span><span class="p">,</span> <span class="s1">'prediction'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">valid</span><span class="p">[</span><span class="s1">'target'</span><span class="p">],</span> <span class="n">valid</span><span class="p">[</span><span class="s1">'prediction'</span><span class="p">])</span>
<span class="n">F1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">valid</span><span class="p">[</span><span class="s1">'target'</span><span class="p">],</span> <span class="n">valid</span><span class="p">[</span><span class="s1">'prediction'</span><span class="p">])</span>
<span class="n">accuracy</span><span class="p">,</span> <span class="n">F1</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(0.6743697478991597, 0.5558739255014327)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>67.44%</code> accuracy; we've gotten better! Notice that our F1 score has gone up also, from <code>0.48</code> to <code>0.56</code>.</p>
<p>For the last of the TF-IDF similarities, let's see how things go if we use the tweets that were preprocessed with SpaCy:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="TF-IDF-with-SpaCy-Tweets">
<a class="anchor" href="#TF-IDF-with-SpaCy-Tweets" aria-hidden="true"><span class="octicon octicon-link"></span></a>TF-IDF with SpaCy Tweets<a class="anchor-link" href="#TF-IDF-with-SpaCy-Tweets"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Same process as before, let's clear the old predictions from <code>valid</code> and skip to the metrics!</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">valid</span> <span class="o">=</span> <span class="n">valid</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">'prediction'</span><span class="p">])</span>
<span class="n">valid</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>index</th>
      <th>id</th>
      <th>keyword</th>
      <th>location</th>
      <th>text</th>
      <th>target</th>
      <th>text_simple</th>
      <th>text_spacy</th>
      <th>text_trigram</th>
      <th>text_trigram_simple</th>
      <th>text_trigram_spacy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5830</td>
      <td>8329</td>
      <td>rubble</td>
      <td>West Africa</td>
      <td>#TNN: China's Stock Market Crash: Are There Ge...</td>
      <td>1</td>
      <td>tnn china s stock market crash are there gems ...</td>
      <td># tnn : china stock market crash : gem rubble ...</td>
      <td>#TNN: China's Stock Market Crash: Are There Ge...</td>
      <td>tnn china s stock market crash are there gems ...</td>
      <td># tnn : china stock market crash : gem rubble ...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2548</td>
      <td>3656</td>
      <td>destroy</td>
      <td>Honduras</td>
      <td>Black Ops 3 SEARCH AND DESTROY GAMEPLAY! (Hunt...</td>
      <td>0</td>
      <td>black ops 3 search and destroy gameplay hunted...</td>
      <td>black ops 3 search destroy gameplay ! ( hunt s...</td>
      <td>Black Ops 3 SEARCH AND DESTROY GAMEPLAY! (Hunt...</td>
      <td>black ops 3 search and destroy gameplay hunted...</td>
      <td>black ops 3 search destroy gameplay ! ( hunt s...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2644</td>
      <td>3796</td>
      <td>destruction</td>
      <td>NaN</td>
      <td>So you have a new weapon that can cause un-ima...</td>
      <td>1</td>
      <td>so you have a new weapon that can cause un ima...</td>
      <td>new weapon cause un - imaginable destruction .</td>
      <td>So you have a new weapon that can cause un-ima...</td>
      <td>so you have a new weapon that can cause un ima...</td>
      <td>new weapon cause un - imaginable destruction .</td>
    </tr>
    <tr>
      <th>3</th>
      <td>6078</td>
      <td>8684</td>
      <td>sinkhole</td>
      <td>Haddonfield, NJ</td>
      <td>Georgia sinkhole closes road swallows whole po...</td>
      <td>1</td>
      <td>georgia sinkhole closes road swallows whole pond</td>
      <td>georgia sinkhole close road swallow pond http:...</td>
      <td>Georgia sinkhole closes road swallows whole po...</td>
      <td>georgia sinkhole closes road swallows whole pond</td>
      <td>georgia sinkhole close road swallow pond http:...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>6531</td>
      <td>9342</td>
      <td>survived</td>
      <td>London</td>
      <td>Survived another tube strike with the last per...</td>
      <td>0</td>
      <td>survived another tube strike with the last per...</td>
      <td>survive tube strike person office reach home ....</td>
      <td>Survived another tube strike with the last per...</td>
      <td>survived another tube strike with the last per...</td>
      <td>survive tube strike person office reach home ....</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">disaster_tweets</span> <span class="o">=</span> <span class="n">disasters</span><span class="p">[</span><span class="s1">'text_spacy'</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">not_disaster_tweets</span> <span class="o">=</span> <span class="n">not_disasters</span><span class="p">[</span><span class="s1">'text_spacy'</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

<span class="n">disaster_tweets_split</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tweet</span><span class="o">.</span><span class="n">split</span><span class="p">()]</span>
    <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="n">disaster_tweets</span>
<span class="p">]</span>
<span class="n">not_disaster_tweets_split</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tweet</span><span class="o">.</span><span class="n">split</span><span class="p">()]</span>
    <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="n">not_disaster_tweets</span>
<span class="p">]</span>

<span class="n">disaster_tweets_word_frequency</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="n">disaster_tweets_split</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tweet</span><span class="p">:</span>
        <span class="n">disaster_tweets_word_frequency</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
        
<span class="n">not_disaster_tweets_word_frequency</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="n">not_disaster_tweets_split</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tweet</span><span class="p">:</span>
        <span class="n">not_disaster_tweets_word_frequency</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="n">disaster_tweets_split</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tweet</span> <span class="k">if</span> <span class="n">disaster_tweets_word_frequency</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="n">disaster_tweets_split</span>
<span class="p">]</span>

<span class="n">not_disaster_tweets_split</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tweet</span> <span class="k">if</span> <span class="n">not_disaster_tweets_word_frequency</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="n">not_disaster_tweets_split</span>
<span class="p">]</span>

<span class="n">disaster_tweets_dct</span> <span class="o">=</span> <span class="n">Dictionary</span><span class="p">(</span><span class="n">disaster_tweets_split</span><span class="p">)</span>
<span class="n">not_disaster_tweets_dct</span> <span class="o">=</span> <span class="n">Dictionary</span><span class="p">(</span><span class="n">not_disaster_tweets_split</span><span class="p">)</span>

<span class="n">disaster_tweets_corpus</span> <span class="o">=</span> <span class="p">[</span><span class="n">disaster_tweets_dct</span><span class="o">.</span><span class="n">doc2bow</span><span class="p">(</span><span class="n">tweet</span><span class="p">)</span> <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="n">disaster_tweets_split</span><span class="p">]</span>
<span class="n">not_disaster_tweets_corpus</span> <span class="o">=</span> <span class="p">[</span><span class="n">not_disaster_tweets_dct</span><span class="o">.</span><span class="n">doc2bow</span><span class="p">(</span><span class="n">tweet</span><span class="p">)</span> <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="n">not_disaster_tweets_split</span><span class="p">]</span>

<span class="n">disaster_tweets_tfidf</span> <span class="o">=</span> <span class="n">TfidfModel</span><span class="p">(</span><span class="n">disaster_tweets_corpus</span><span class="p">)</span>
<span class="n">not_disaster_tweets_tfidf</span> <span class="o">=</span> <span class="n">TfidfModel</span><span class="p">(</span><span class="n">not_disaster_tweets_corpus</span><span class="p">)</span>

<span class="n">disaster_tweets_tfidf_vectors</span> <span class="o">=</span> <span class="n">disaster_tweets_tfidf</span><span class="p">[</span><span class="n">disaster_tweets_corpus</span><span class="p">]</span>
<span class="n">not_disaster_tweets_tfidf_vectors</span> <span class="o">=</span> <span class="n">not_disaster_tweets_tfidf</span><span class="p">[</span><span class="n">not_disaster_tweets_corpus</span><span class="p">]</span>

<span class="n">disaster_tweets_similarity</span> <span class="o">=</span> <span class="n">MatrixSimilarity</span><span class="p">(</span><span class="n">disaster_tweets_tfidf_vectors</span><span class="p">)</span>
<span class="n">not_disaster_tweets_similarity</span> <span class="o">=</span> <span class="n">MatrixSimilarity</span><span class="p">(</span><span class="n">not_disaster_tweets_tfidf_vectors</span><span class="p">)</span>

<span class="n">valid_tweets</span> <span class="o">=</span> <span class="n">valid</span><span class="p">[</span><span class="s1">'text_spacy'</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

<span class="n">valid_tweets_split</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tweet</span><span class="o">.</span><span class="n">split</span><span class="p">()]</span>
    <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="n">valid_tweets</span>
<span class="p">]</span>

<span class="n">valid_tweets_word_frequency</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="n">valid_tweets_split</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tweet</span><span class="p">:</span>
        <span class="n">valid_tweets_word_frequency</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
    
<span class="n">valid_tweets_split</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tweet</span> <span class="k">if</span> <span class="n">valid_tweets_word_frequency</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="n">valid_tweets_split</span>
<span class="p">]</span>

<span class="n">valid</span><span class="p">[</span><span class="s1">'prediction'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">valid</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">'int'</span><span class="p">)</span>

<span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">valid</span><span class="p">)):</span>
    <span class="n">tweet</span> <span class="o">=</span> <span class="n">valid_tweets_split</span><span class="p">[</span><span class="n">row</span><span class="p">]</span>
    
    <span class="n">tweet_bow_with_disasters_dct</span> <span class="o">=</span> <span class="n">disaster_tweets_dct</span><span class="o">.</span><span class="n">doc2bow</span><span class="p">(</span><span class="n">tweet</span><span class="p">)</span>
    <span class="n">tweet_bow_with_not_disasters_dct</span> <span class="o">=</span> <span class="n">not_disaster_tweets_dct</span><span class="o">.</span><span class="n">doc2bow</span><span class="p">(</span><span class="n">tweet</span><span class="p">)</span>
    
    <span class="n">tweet_tfidf_vector_with_disasters_tfidf</span> <span class="o">=</span> <span class="n">disaster_tweets_tfidf</span><span class="p">[</span><span class="n">tweet_bow_with_disasters_dct</span><span class="p">]</span>
    <span class="n">tweet_tfidf_vector_with_not_disasters_tfidf</span> <span class="o">=</span> <span class="n">not_disaster_tweets_tfidf</span><span class="p">[</span><span class="n">tweet_bow_with_not_disasters_dct</span><span class="p">]</span>
    
    <span class="n">disaster_similarity_vector</span> <span class="o">=</span> <span class="n">disaster_tweets_similarity</span><span class="p">[</span><span class="n">tweet_tfidf_vector_with_disasters_tfidf</span><span class="p">]</span>
    <span class="n">not_disaster_similarity_vector</span> <span class="o">=</span> <span class="n">not_disaster_tweets_similarity</span><span class="p">[</span><span class="n">tweet_tfidf_vector_with_not_disasters_tfidf</span><span class="p">]</span>
    
    <span class="n">disaster_tally</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">disaster_similarity_vector</span> <span class="o">&gt;</span> <span class="mf">0.1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size</span> <span class="c1"># np.where() returns a tuple, so we have to index into [0] to get what we want</span>
    <span class="n">not_disaster_tally</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">not_disaster_similarity_vector</span> <span class="o">&gt;</span> <span class="mf">0.1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size</span>
    
    <span class="k">if</span> <span class="n">disaster_tally</span> <span class="o">&gt;</span> <span class="n">not_disaster_tally</span><span class="p">:</span>
        <span class="n">valid</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">row</span><span class="p">,</span> <span class="s1">'prediction'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">valid</span><span class="p">[</span><span class="s1">'target'</span><span class="p">],</span> <span class="n">valid</span><span class="p">[</span><span class="s1">'prediction'</span><span class="p">])</span>
<span class="n">F1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">valid</span><span class="p">[</span><span class="s1">'target'</span><span class="p">],</span> <span class="n">valid</span><span class="p">[</span><span class="s1">'prediction'</span><span class="p">])</span>
<span class="n">accuracy</span><span class="p">,</span> <span class="n">F1</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(0.6559873949579832, 0.4988523335883704)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>With SpaCy lemmatization and removal of stop words, our accuracy and F1 scores have ended up between the unprocessed and "simple" datasets, with an accuracy of <code>65.60%</code> and an F1 score of <code>0.50</code>.</p>
<p>So it seems of the three preprocessing techniques used in a TF-IDF model, in this case, "simple" cleaning worked the best with an accuracy of <code>67.44</code> and an F1 score of <code>0.56</code>.</p>
<p>Let's now move forward with Word2Vec.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Word2Vec">
<a class="anchor" href="#Word2Vec" aria-hidden="true"><span class="octicon octicon-link"></span></a>Word2Vec<a class="anchor-link" href="#Word2Vec"> </a>
</h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">gensim.models</span> <span class="kn">import</span> <span class="n">Word2Vec</span>
<span class="kn">from</span> <span class="nn">gensim.models.phrases</span> <span class="kn">import</span> <span class="n">Phrases</span><span class="p">,</span> <span class="n">Phraser</span>
<span class="kn">import</span> <span class="nn">time</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The second method for text classification that we'll use is <strong>word vectors</strong>.</p>
<p>Word vectors were first introduced by Mikolov et al.<a href="https://arxiv.org/pdf/1301.3781.pdf">[1]</a><a href="https://arxiv.org/pdf/1310.4546.pdf">[2]</a> and provide highly accurate results in word similarity tasks at relatively low computational cost. You can think of a word vector as a 1-dimensional matrix of numbers of some arbitrary length computed by neural networks. Word similarity is then determined by the <a href="https://en.wikipedia.org/wiki/Cosine_similarity">cosine distance</a> between two vectors.</p>
<p>Word vectors, interestingly, can encode linguistic regularities and patterns. Therefore, many of these patterns can be represented as linear translations. For example <code>vector(king) - vector(man) + vector(woman)</code> is going to very close to <code>vector(queen)</code>. This is surprising!</p>
<p>Let's see how word vectors do at predicting disaster tweets.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Word2Vec-Preprocessing">
<a class="anchor" href="#Word2Vec-Preprocessing" aria-hidden="true"><span class="octicon octicon-link"></span></a>Word2Vec Preprocessing<a class="anchor-link" href="#Word2Vec-Preprocessing"> </a>
</h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We'll be using gensim's Word2Vec module, which processes text using a <code>min_count</code> parameter. This parameter only includes words in the input that occur more than the set <code>min_count</code> number of times. This will cause problems later on when trying to classify the tweets in the validation set because some of the words will have occurred less than the <code>min_count</code> parameter, throwing an "out-of-vocabulary" (OOV) error.</p>
<p>In order to remedy this, we have two options:</p>
<ol>
<li>Train the Word2Vec model and then remove the words from the validation tweets that are not in the trained vocabulary.</li>
<li>Preemptively change the words in our corpus that occur less than the expected <code>min_count</code> number of times with some sort of "unknown" character.</li>
</ol>
<p>Both of these methods alter the original tweet that we'll be classifying, but the latter option seems to adhere closer to the original meaning of the tweet. If we drop words, we could make an entirely new sentence with an enitrely new grammatical structure and meaning. Whereas if we replace the words that occur less than <code>min_count</code> amount of times with an unknown character, the original grammatical structure of each sentence is held in tact, creating a closer tie to the tweet's original meaning.</p>
<p>To do this efficiently, I've created a function <code>replace_unknowns()</code> that replaces the words in a text which occur less than a specified <code>min_count</code> number of times with <code>'UNK'</code>. We can use this to alter the preprocessed columns that we made earlier and store them in our original <code>data</code> DataFrame.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">replace_unknowns</span><span class="p">(</span><span class="n">search_texts</span><span class="p">,</span> <span class="n">min_count</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Replaces words that occur less than a certain number of times</span>
<span class="sd">    in a string or list of strings with 'UNK'.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    search_texts : list</span>
<span class="sd">        A list of input strings to iterate over.</span>
<span class="sd">    min_count : int</span>
<span class="sd">        An integer specify the minimum count a word should occur in</span>
<span class="sd">        the search_texts to not be replaced with 'UNK'.</span>
<span class="sd">    </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    list</span>
<span class="sd">        List of search_texts with words that occur less than the min_count</span>
<span class="sd">        amount of times replaced with 'UNK'.</span>
<span class="sd">    </span>
<span class="sd">    """</span>
    
    <span class="c1"># Get all tweets lowered and tokenized.</span>
    <span class="c1"># This makes sense because we'd never want to</span>
    <span class="c1"># treat an 'a' different from an 'A'.</span>
    <span class="c1"># (Capitalization is just an orthographical convention)</span>
    <span class="n">texts</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'\s+'</span><span class="p">,</span> <span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">())]</span>
        <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">search_texts</span>
    <span class="p">]</span>

    <span class="c1"># create a dictionary that stores the count of each</span>
    <span class="c1"># word in our uncleaned tweets. We can insert new words</span>
    <span class="c1"># into the dict or add to their count if their already in it.</span>
    <span class="n">vocab_counts</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

    <span class="c1"># Create a list that we can append words that occur more than</span>
    <span class="c1"># the desired threshold number of times to.</span>
    <span class="n">vocab</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">texts</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">text</span><span class="p">:</span>
            <span class="n">vocab_counts</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="c1"># Now go through the vocab_counts and get rid of</span>
    <span class="c1"># words that occur less than five times.</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">vocab_counts</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">vocab_counts</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">min_count</span><span class="p">:</span>
            <span class="n">vocab</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>

    <span class="c1"># Now initialize a new column in data that will hold</span>
    <span class="c1"># the tweets with 'UNK' replacing words that occur</span>
    <span class="c1"># across the entire vocabulary less than five times.</span>
    <span class="c1"># This creates congruency later on in the model.</span>
    <span class="c1"># data['text_count_5'] = np.empty(len(data), dtype=str) # ***** DO THIS OUTSIDE FUNC IN WORD2VEC SECTION</span>

    <span class="c1"># Now, go through each tweet and replace the words that</span>
    <span class="c1"># occur less than 5 times throughout the entire corpus</span>
    <span class="c1"># with 'UNK'. Then, we insert the new tweet into a new</span>
    <span class="c1"># column in the original dataframe.</span>

    <span class="n">out</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># this process takes about a minute</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">text</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">texts</span><span class="p">):</span>
        <span class="n">text_replaced</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">text</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">vocab</span><span class="p">:</span>
                <span class="n">text_replaced</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">text_replaced</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">'UNK'</span><span class="p">)</span>
        <span class="n">text_replaced</span> <span class="o">=</span> <span class="s1">' '</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">text_replaced</span><span class="p">)</span>
        <span class="n">out</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">text_replaced</span><span class="p">)</span>
        
    <span class="k">return</span> <span class="n">out</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Below, we'll use <code>min_count=5</code> as one of our <a href="https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning">hyperparameters</a>) in our Word2Vec model, so let's replace all of the words in all three of our preprocessed tweet columns (<code>text_trigram</code>, <code>text_trigram_simple</code>, and <code>text_trigram_spacy</code>) in each DataFrame with <code>'UNK'</code>.
</p>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>Remember! We’re using the trigrams we built in the Data Augmentation section. If you skipped it, go back now!
</div>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>Normally this would happen during the initial preprocessing stage, allowing us to only need to call <code>replace_unknowns()</code> on our initial <code>data</code> DataFrame. Because we’re calling <code>replace_unknowns()</code> after we’ve already split our data into training and validation sets, we need to call the function on all of the DataFrames we’ve already created.
</div>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data</span><span class="p">[</span><span class="s1">'text_count_5'</span><span class="p">]</span> <span class="o">=</span> <span class="n">replace_unknowns</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">'text_trigram'</span><span class="p">],</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">data</span><span class="p">[</span><span class="s1">'text_simple_5'</span><span class="p">]</span> <span class="o">=</span> <span class="n">replace_unknowns</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">'text_trigram_simple'</span><span class="p">],</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">data</span><span class="p">[</span><span class="s1">'text_spacy_5'</span><span class="p">]</span> <span class="o">=</span> <span class="n">replace_unknowns</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">'text_trigram_spacy'</span><span class="p">],</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>keyword</th>
      <th>location</th>
      <th>text</th>
      <th>target</th>
      <th>text_simple</th>
      <th>text_spacy</th>
      <th>text_trigram</th>
      <th>text_trigram_simple</th>
      <th>text_trigram_spacy</th>
      <th>text_count_5</th>
      <th>text_simple_5</th>
      <th>text_spacy_5</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Our Deeds are the Reason of this #earthquake M...</td>
      <td>1</td>
      <td>our deeds are the reason of this earthquake ma...</td>
      <td>deed reason # earthquake allah forgive</td>
      <td>Our Deeds are the Reason of this #earthquake M...</td>
      <td>our deeds are the reason of this earthquake ma...</td>
      <td>deed reason # earthquake allah forgive</td>
      <td>our UNK are the reason of this #earthquake may...</td>
      <td>our UNK are the reason of this earthquake may ...</td>
      <td>UNK reason # earthquake allah UNK</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Forest fire near La Ronge Sask. Canada</td>
      <td>1</td>
      <td>forest fire near la ronge sask canada</td>
      <td>forest fire near la ronge sask . canada</td>
      <td>Forest fire near La Ronge Sask. Canada</td>
      <td>forest fire near la ronge sask canada</td>
      <td>forest fire near la ronge sask . canada</td>
      <td>forest fire near la UNK UNK canada</td>
      <td>forest fire near la UNK UNK canada</td>
      <td>forest fire near la UNK UNK . canada</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>All residents asked to 'shelter in place' are ...</td>
      <td>1</td>
      <td>all residents asked to shelter in place are be...</td>
      <td>resident ask ' shelter place ' notify officer ...</td>
      <td>All residents asked to 'shelter in place' are ...</td>
      <td>all residents asked to shelter in place are be...</td>
      <td>resident ask ' shelter place ' notify officer ...</td>
      <td>all residents asked to UNK in UNK are being UN...</td>
      <td>all residents asked to shelter in place are be...</td>
      <td>resident ask ' shelter place ' UNK officer . e...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>6</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>13,000 people receive #wildfires evacuation or...</td>
      <td>1</td>
      <td>13 000 people receive wildfires evacuation ord...</td>
      <td>13,000 people receive # wildfire evacuation or...</td>
      <td>13,000 people receive #wildfires evacuation or...</td>
      <td>13 000 people receive wildfires evacuation ord...</td>
      <td>13,000 people receive # wildfire evacuation or...</td>
      <td>UNK people UNK UNK evacuation orders in califo...</td>
      <td>13 UNK people UNK wildfires evacuation orders ...</td>
      <td>UNK people UNK # wildfire evacuation order cal...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>7</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Just got sent this photo from Ruby #Alaska as ...</td>
      <td>1</td>
      <td>just got sent this photo from ruby alaska as s...</td>
      <td>get send photo ruby # alaska smoke # wildfire ...</td>
      <td>Just got sent this photo from Ruby #Alaska as ...</td>
      <td>just got sent this photo from ruby alaska as s...</td>
      <td>get send photo ruby # alaska smoke # wildfire ...</td>
      <td>just got sent this photo from UNK UNK as smoke...</td>
      <td>just got sent this photo from UNK alaska as sm...</td>
      <td>get send photo UNK # alaska smoke # wildfire U...</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">valid</span><span class="p">[</span><span class="s1">'text_count_5'</span><span class="p">]</span> <span class="o">=</span> <span class="n">replace_unknowns</span><span class="p">(</span><span class="n">valid</span><span class="p">[</span><span class="s1">'text_trigram'</span><span class="p">],</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">valid</span><span class="p">[</span><span class="s1">'text_simple_5'</span><span class="p">]</span> <span class="o">=</span> <span class="n">replace_unknowns</span><span class="p">(</span><span class="n">valid</span><span class="p">[</span><span class="s1">'text_trigram_simple'</span><span class="p">],</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">valid</span><span class="p">[</span><span class="s1">'text_spacy_5'</span><span class="p">]</span> <span class="o">=</span> <span class="n">replace_unknowns</span><span class="p">(</span><span class="n">valid</span><span class="p">[</span><span class="s1">'text_trigram_spacy'</span><span class="p">],</span> <span class="mi">5</span><span class="p">)</span>

<span class="n">disasters</span><span class="p">[</span><span class="s1">'text_count_5'</span><span class="p">]</span> <span class="o">=</span> <span class="n">replace_unknowns</span><span class="p">(</span><span class="n">disasters</span><span class="p">[</span><span class="s1">'text_trigram'</span><span class="p">],</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">disasters</span><span class="p">[</span><span class="s1">'text_simple_5'</span><span class="p">]</span> <span class="o">=</span> <span class="n">replace_unknowns</span><span class="p">(</span><span class="n">disasters</span><span class="p">[</span><span class="s1">'text_trigram_simple'</span><span class="p">],</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">disasters</span><span class="p">[</span><span class="s1">'text_spacy_5'</span><span class="p">]</span> <span class="o">=</span> <span class="n">replace_unknowns</span><span class="p">(</span><span class="n">disasters</span><span class="p">[</span><span class="s1">'text_trigram_spacy'</span><span class="p">],</span> <span class="mi">5</span><span class="p">)</span>

<span class="n">not_disasters</span><span class="p">[</span><span class="s1">'text_count_5'</span><span class="p">]</span> <span class="o">=</span> <span class="n">replace_unknowns</span><span class="p">(</span><span class="n">not_disasters</span><span class="p">[</span><span class="s1">'text_trigram'</span><span class="p">],</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">not_disasters</span><span class="p">[</span><span class="s1">'text_simple_5'</span><span class="p">]</span> <span class="o">=</span> <span class="n">replace_unknowns</span><span class="p">(</span><span class="n">not_disasters</span><span class="p">[</span><span class="s1">'text_trigram_simple'</span><span class="p">],</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">not_disasters</span><span class="p">[</span><span class="s1">'text_spacy_5'</span><span class="p">]</span> <span class="o">=</span> <span class="n">replace_unknowns</span><span class="p">(</span><span class="n">not_disasters</span><span class="p">[</span><span class="s1">'text_trigram_spacy'</span><span class="p">],</span> <span class="mi">5</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Great, now our data is set up and ready to be used with a Word2Vec model!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Word2Vec-with-Unprocessed-Tweets">
<a class="anchor" href="#Word2Vec-with-Unprocessed-Tweets" aria-hidden="true"><span class="octicon octicon-link"></span></a>Word2Vec with Unprocessed Tweets<a class="anchor-link" href="#Word2Vec-with-Unprocessed-Tweets"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>First and foremost, let's get rid of the <code>valid['prediction']</code> column that we made using TF-IDF.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">valid</span> <span class="o">=</span> <span class="n">valid</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">'prediction'</span><span class="p">])</span>
<span class="n">valid</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>index</th>
      <th>id</th>
      <th>keyword</th>
      <th>location</th>
      <th>text</th>
      <th>target</th>
      <th>text_simple</th>
      <th>text_spacy</th>
      <th>text_trigram</th>
      <th>text_trigram_simple</th>
      <th>text_trigram_spacy</th>
      <th>text_count_5</th>
      <th>text_simple_5</th>
      <th>text_spacy_5</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5830</td>
      <td>8329</td>
      <td>rubble</td>
      <td>West Africa</td>
      <td>#TNN: China's Stock Market Crash: Are There Ge...</td>
      <td>1</td>
      <td>tnn china s stock market crash are there gems ...</td>
      <td># tnn : china stock market crash : gem rubble ...</td>
      <td>#TNN: China's Stock Market Crash: Are There Ge...</td>
      <td>tnn china s stock market crash are there gems ...</td>
      <td># tnn : china stock market crash : gem rubble ...</td>
      <td>UNK china's stock market crash: are there gems...</td>
      <td>UNK china s stock market crash are there gems ...</td>
      <td># UNK : china stock market crash : gem rubble ...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2548</td>
      <td>3656</td>
      <td>destroy</td>
      <td>Honduras</td>
      <td>Black Ops 3 SEARCH AND DESTROY GAMEPLAY! (Hunt...</td>
      <td>0</td>
      <td>black ops 3 search and destroy gameplay hunted...</td>
      <td>black ops 3 search destroy gameplay ! ( hunt s...</td>
      <td>Black Ops 3 SEARCH AND DESTROY GAMEPLAY! (Hunt...</td>
      <td>black ops 3 search and destroy gameplay hunted...</td>
      <td>black ops 3 search destroy gameplay ! ( hunt s...</td>
      <td>black UNK 3 UNK and destroy UNK UNK UNK UNK UN...</td>
      <td>black UNK 3 UNK and destroy UNK UNK UNK UNK UNK</td>
      <td>black UNK 3 UNK destroy UNK ! ( UNK UNK UNK UN...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2644</td>
      <td>3796</td>
      <td>destruction</td>
      <td>NaN</td>
      <td>So you have a new weapon that can cause un-ima...</td>
      <td>1</td>
      <td>so you have a new weapon that can cause un ima...</td>
      <td>new weapon cause un - imaginable destruction .</td>
      <td>So you have a new weapon that can cause un-ima...</td>
      <td>so you have a new weapon that can cause un ima...</td>
      <td>new weapon cause un - imaginable destruction .</td>
      <td>so you have a new weapon that can cause UNK UNK</td>
      <td>so you have a new weapon that can cause UNK UN...</td>
      <td>new weapon cause UNK - UNK destruction .</td>
    </tr>
    <tr>
      <th>3</th>
      <td>6078</td>
      <td>8684</td>
      <td>sinkhole</td>
      <td>Haddonfield, NJ</td>
      <td>Georgia sinkhole closes road swallows whole po...</td>
      <td>1</td>
      <td>georgia sinkhole closes road swallows whole pond</td>
      <td>georgia sinkhole close road swallow pond http:...</td>
      <td>Georgia sinkhole closes road swallows whole po...</td>
      <td>georgia sinkhole closes road swallows whole pond</td>
      <td>georgia sinkhole close road swallow pond http:...</td>
      <td>UNK sinkhole UNK road UNK whole UNK UNK</td>
      <td>UNK sinkhole UNK road UNK whole UNK</td>
      <td>UNK sinkhole close road swallow UNK UNK</td>
    </tr>
    <tr>
      <th>4</th>
      <td>6531</td>
      <td>9342</td>
      <td>survived</td>
      <td>London</td>
      <td>Survived another tube strike with the last per...</td>
      <td>0</td>
      <td>survived another tube strike with the last per...</td>
      <td>survive tube strike person office reach home ....</td>
      <td>Survived another tube strike with the last per...</td>
      <td>survived another tube strike with the last per...</td>
      <td>survive tube strike person office reach home ....</td>
      <td>survived another UNK strike with the last pers...</td>
      <td>survived another UNK strike with the last pers...</td>
      <td>survive UNK strike person UNK UNK home . get w...</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Initialize our Word2Vec model.
</p>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>I’m splitting up the training of the model into three steps. See <a href="https://www.kaggle.com/pierremegret/gensim-word2vec-tutorial/comments">this notebook</a> for more details on why (and Word2Vec in general).
</div>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Word2Vec</span><span class="p">(</span><span class="n">min_count</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">sample</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">workers</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Build the vocab for our model.</p>
<p>The <code>.build_vocab()</code> method expects an iterable of a list of strings as its input, so first we split our tweets to adhere to that. Notice that we're looping through all of the tweets in our original <code>data</code> DataFrame rather than the <code>train</code> DataFrame we created. This is because we need the vocabulary of <em>all</em> tweets (in both the training and validation data) in order to properly compare tweets in the training data to tweets in the validation data. If we just built our model on the training data, many of the words in the validation tweets would throw OOV errors!</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tweets</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="n">wd</span> <span class="k">for</span> <span class="n">wd</span> <span class="ow">in</span> <span class="n">tweet</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">' '</span><span class="p">)]</span>
    <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[</span><span class="s1">'text_count_5'</span><span class="p">]</span>
<span class="p">]</span>

<span class="n">model</span><span class="o">.</span><span class="n">build_vocab</span><span class="p">(</span><span class="n">tweets</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we can train the model over 30 epochs (cycles).</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">tweets</span><span class="p">,</span> <span class="n">total_examples</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">corpus_count</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(2006980, 3383040)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we normalize vectors in the vocaulary for consistency.
</p>
<div class="flash flash-warn">
    <svg class="octicon octicon-zap octicon octicon-zap" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M10.561 1.5a.016.016 0 00-.01.004L3.286 8.571A.25.25 0 003.462 9H6.75a.75.75 0 01.694 1.034l-1.713 4.188 6.982-6.793A.25.25 0 0012.538 7H9.25a.75.75 0 01-.683-1.06l2.008-4.418.003-.006a.02.02 0 00-.004-.009.02.02 0 00-.006-.006L10.56 1.5zM9.504.43a1.516 1.516 0 012.437 1.713L10.415 5.5h2.123c1.57 0 2.346 1.909 1.22 3.004l-7.34 7.142a1.25 1.25 0 01-.871.354h-.302a1.25 1.25 0 01-1.157-1.723L5.633 10.5H3.462c-1.57 0-2.346-1.909-1.22-3.004L9.503.429z"></path></svg>
    <strong>Important: </strong>You wouldn’t do this if you were going to train further down the line. See <a href="https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/online_w2v_tutorial.ipynb">this notebook</a> for more information about expanding your model’s vocabulary.
</div>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">init_sims</span><span class="p">(</span><span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we can make our predictions.</p>
<p>Just as when we were doing TF-IDF, we need to initialize a <code>prediction</code> column in the <code>valid</code> DataFrame to store our predictions.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">valid</span><span class="p">[</span><span class="s1">'prediction'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">valid</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">'int'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Similar to how we predicted whether a tweet was a disaster or not with TF-IDF, we have to compare each tweet in the validation data with each tweet in both the <code>disasters</code> DataFrame and the <code>not_disasters</code> DataFrame.</p>
<p>So, this time, for each tweet, we:</p>
<ol>
<li>Split the validation tweet on all whitespace characters.</li>
<li>Calculate the similarity between the validation tweet and each disaster and non-disaster tweet (also split on whitespace characters).</li>
<li>If the similarity between the two tweets is greater than 0.7, add to that tweet set's tally.</li>
<li>If the disaster tally is gerater than the non-disaster tally, we change the value of the prediction column for the validation tweet to 1 (otherwise, it remains 0, indicating a non-disastrous guess).</li>
</ol>
<p>This is exemplified below:
</p>
<div class="flash flash-warn">
    <svg class="octicon octicon-zap octicon octicon-zap octicon octicon-zap" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M10.561 1.5a.016.016 0 00-.01.004L3.286 8.571A.25.25 0 003.462 9H6.75a.75.75 0 01.694 1.034l-1.713 4.188 6.982-6.793A.25.25 0 0012.538 7H9.25a.75.75 0 01-.683-1.06l2.008-4.418.003-.006a.02.02 0 00-.004-.009.02.02 0 00-.006-.006L10.56 1.5zM9.504.43a1.516 1.516 0 012.437 1.713L10.415 5.5h2.123c1.57 0 2.346 1.909 1.22 3.004l-7.34 7.142a1.25 1.25 0 01-.871.354h-.302a1.25 1.25 0 01-1.157-1.723L5.633 10.5H3.462c-1.57 0-2.346-1.909-1.22-3.004L9.503.429z"></path></svg>
    <strong>Important: </strong>This model takes a little bit of time to train. It took almost 16 minutes on my machine.
</div>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="k">for</span> <span class="n">valid_row</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">valid</span><span class="p">)):</span>
    <span class="n">valid_tweet</span> <span class="o">=</span> <span class="n">valid</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">valid_row</span><span class="p">,</span> <span class="s1">'text_count_5'</span><span class="p">]</span>
    <span class="n">tokenized_valid_tweet</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'\s+'</span><span class="p">,</span> <span class="n">valid_tweet</span><span class="p">)</span> <span class="c1"># split on all whitespace characters</span>
    
    <span class="n">disaster_count</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">not_disaster_count</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="c1"># we can just reuse "disasters" and</span>
    <span class="c1"># "not_disasters" from earlier!</span>
    <span class="k">for</span> <span class="n">disaster_row</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">disasters</span><span class="p">)):</span>
        <span class="n">disaster_tweet</span> <span class="o">=</span> <span class="n">disasters</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">disaster_row</span><span class="p">,</span> <span class="s1">'text_count_5'</span><span class="p">]</span>
        <span class="n">tokenized_disaster_tweet</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'\s+'</span><span class="p">,</span> <span class="n">disaster_tweet</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">model</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">n_similarity</span><span class="p">(</span><span class="n">tokenized_valid_tweet</span><span class="p">,</span> <span class="n">tokenized_disaster_tweet</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">0.7</span><span class="p">:</span>
            <span class="n">disaster_count</span> <span class="o">+=</span> <span class="mi">1</span>
        
    <span class="k">for</span> <span class="n">not_disaster_row</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">not_disasters</span><span class="p">)):</span>
        <span class="n">not_disaster_tweet</span> <span class="o">=</span> <span class="n">not_disasters</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">not_disaster_row</span><span class="p">,</span> <span class="s1">'text_count_5'</span><span class="p">]</span>
        <span class="n">tokenized_not_disaster_tweet</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'\s+'</span><span class="p">,</span> <span class="n">not_disaster_tweet</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">model</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">n_similarity</span><span class="p">(</span><span class="n">tokenized_valid_tweet</span><span class="p">,</span> <span class="n">tokenized_not_disaster_tweet</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">0.7</span><span class="p">:</span>
            <span class="n">not_disaster_count</span> <span class="o">+=</span> <span class="mi">1</span>
            
    <span class="k">if</span> <span class="n">disaster_count</span> <span class="o">&gt;</span> <span class="n">not_disaster_count</span><span class="p">:</span>
        <span class="n">valid</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">valid_row</span><span class="p">,</span> <span class="s1">'prediction'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
        
<span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Runtime: </span><span class="si">{</span><span class="p">(</span><span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">)</span> <span class="o">/</span> <span class="mf">60.0</span><span class="si">}</span><span class="s1"> mins'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Runtime: 17.87487813234329 mins
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now let's take another look at the <code>valid</code> DataFrame to see if we've got some predictions...</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">valid</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>index</th>
      <th>id</th>
      <th>keyword</th>
      <th>location</th>
      <th>text</th>
      <th>target</th>
      <th>text_simple</th>
      <th>text_spacy</th>
      <th>text_trigram</th>
      <th>text_trigram_simple</th>
      <th>text_trigram_spacy</th>
      <th>text_count_5</th>
      <th>text_simple_5</th>
      <th>text_spacy_5</th>
      <th>prediction</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5830</td>
      <td>8329</td>
      <td>rubble</td>
      <td>West Africa</td>
      <td>#TNN: China's Stock Market Crash: Are There Ge...</td>
      <td>1</td>
      <td>tnn china s stock market crash are there gems ...</td>
      <td># tnn : china stock market crash : gem rubble ...</td>
      <td>#TNN: China's Stock Market Crash: Are There Ge...</td>
      <td>tnn china s stock market crash are there gems ...</td>
      <td># tnn : china stock market crash : gem rubble ...</td>
      <td>UNK china's stock market crash: are there gems...</td>
      <td>UNK china s stock market crash are there gems ...</td>
      <td># UNK : china stock market crash : gem rubble ...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2548</td>
      <td>3656</td>
      <td>destroy</td>
      <td>Honduras</td>
      <td>Black Ops 3 SEARCH AND DESTROY GAMEPLAY! (Hunt...</td>
      <td>0</td>
      <td>black ops 3 search and destroy gameplay hunted...</td>
      <td>black ops 3 search destroy gameplay ! ( hunt s...</td>
      <td>Black Ops 3 SEARCH AND DESTROY GAMEPLAY! (Hunt...</td>
      <td>black ops 3 search and destroy gameplay hunted...</td>
      <td>black ops 3 search destroy gameplay ! ( hunt s...</td>
      <td>black UNK 3 UNK and destroy UNK UNK UNK UNK UN...</td>
      <td>black UNK 3 UNK and destroy UNK UNK UNK UNK UNK</td>
      <td>black UNK 3 UNK destroy UNK ! ( UNK UNK UNK UN...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2644</td>
      <td>3796</td>
      <td>destruction</td>
      <td>NaN</td>
      <td>So you have a new weapon that can cause un-ima...</td>
      <td>1</td>
      <td>so you have a new weapon that can cause un ima...</td>
      <td>new weapon cause un - imaginable destruction .</td>
      <td>So you have a new weapon that can cause un-ima...</td>
      <td>so you have a new weapon that can cause un ima...</td>
      <td>new weapon cause un - imaginable destruction .</td>
      <td>so you have a new weapon that can cause UNK UNK</td>
      <td>so you have a new weapon that can cause UNK UN...</td>
      <td>new weapon cause UNK - UNK destruction .</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>6078</td>
      <td>8684</td>
      <td>sinkhole</td>
      <td>Haddonfield, NJ</td>
      <td>Georgia sinkhole closes road swallows whole po...</td>
      <td>1</td>
      <td>georgia sinkhole closes road swallows whole pond</td>
      <td>georgia sinkhole close road swallow pond http:...</td>
      <td>Georgia sinkhole closes road swallows whole po...</td>
      <td>georgia sinkhole closes road swallows whole pond</td>
      <td>georgia sinkhole close road swallow pond http:...</td>
      <td>UNK sinkhole UNK road UNK whole UNK UNK</td>
      <td>UNK sinkhole UNK road UNK whole UNK</td>
      <td>UNK sinkhole close road swallow UNK UNK</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>6531</td>
      <td>9342</td>
      <td>survived</td>
      <td>London</td>
      <td>Survived another tube strike with the last per...</td>
      <td>0</td>
      <td>survived another tube strike with the last per...</td>
      <td>survive tube strike person office reach home ....</td>
      <td>Survived another tube strike with the last per...</td>
      <td>survived another tube strike with the last per...</td>
      <td>survive tube strike person office reach home ....</td>
      <td>survived another UNK strike with the last pers...</td>
      <td>survived another UNK strike with the last pers...</td>
      <td>survive UNK strike person UNK UNK home . get w...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>7168</td>
      <td>10272</td>
      <td>war%20zone</td>
      <td>We're All Mad Here</td>
      <td>Packing for CT aka my room looks like a war zone</td>
      <td>0</td>
      <td>packing for ct aka my room looks like a war zone</td>
      <td>pack ct aka room look like war zone</td>
      <td>Packing for CT aka my room looks like a war zone</td>
      <td>packing for ct aka my room looks_like a war zone</td>
      <td>pack ct aka room look_like war zone</td>
      <td>UNK for UNK UNK my UNK looks like a war UNK</td>
      <td>UNK for UNK UNK my UNK looks_like a war zone</td>
      <td>UNK UNK UNK UNK look_like war zone</td>
      <td>0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>4140</td>
      <td>5887</td>
      <td>harm</td>
      <td>NaN</td>
      <td>sticks and stones may break my bones\nbut word...</td>
      <td>0</td>
      <td>sticks and stones may break my bones but words...</td>
      <td>stick stone break bone \n word harm</td>
      <td>sticks and stones may break my bones but words...</td>
      <td>sticks and stones may break my bones but words...</td>
      <td>stick stone break bone word harm</td>
      <td>UNK and UNK may UNK my UNK but words will neve...</td>
      <td>UNK and UNK may UNK my UNK but words will neve...</td>
      <td>UNK UNK break UNK word harm</td>
      <td>0</td>
    </tr>
    <tr>
      <th>7</th>
      <td>4999</td>
      <td>7131</td>
      <td>military</td>
      <td>Virginia, USA</td>
      <td>@TeamHendrick @TeamHendrick @RIRInsider Finger...</td>
      <td>0</td>
      <td>teamhendrick teamhendrick ririnsider fingers c...</td>
      <td>@teamhendrick @teamhendrick @ririnsid finger c...</td>
      <td>@TeamHendrick @TeamHendrick @RIRInsider Finger...</td>
      <td>teamhendrick teamhendrick ririnsider fingers c...</td>
      <td>@teamhendrick @teamhendrick @ririnsid finger c...</td>
      <td>UNK UNK UNK UNK UNK that there will_be a UNK f...</td>
      <td>UNK UNK UNK UNK UNK that there will_be a UNK f...</td>
      <td>UNK UNK UNK UNK cross driver UNK military UNK ...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>8</th>
      <td>270</td>
      <td>393</td>
      <td>annihilation</td>
      <td>BIG D  HOUSTON/BOSTON/DENVER</td>
      <td>U.S National Park Services Tonto National Fore...</td>
      <td>0</td>
      <td>u s national park services tonto national fore...</td>
      <td>u.s national park services tonto national fore...</td>
      <td>U.S National Park Services Tonto National Fore...</td>
      <td>u_s national park services tonto national fore...</td>
      <td>u.s national park services tonto national fore...</td>
      <td>UNK national UNK services UNK national UNK sto...</td>
      <td>u_s national UNK services UNK national forest ...</td>
      <td>u.s national UNK UNK UNK national forest : sto...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>9</th>
      <td>3163</td>
      <td>4541</td>
      <td>emergency</td>
      <td>Renfrew, Scotland</td>
      <td>@batfanuk we enjoyed the show today. Great fun...</td>
      <td>0</td>
      <td>batfanuk we enjoyed the show today great fun t...</td>
      <td>@batfanuk enjoy today . great fun . emergency ...</td>
      <td>@batfanuk we enjoyed the show today. Great fun...</td>
      <td>batfanuk we enjoyed the show today great fun t...</td>
      <td>@batfanuk enjoy today . great fun . emergency ...</td>
      <td>UNK we UNK the show today. great UNK the emerg...</td>
      <td>UNK we UNK the show today great fun the emerge...</td>
      <td>UNK enjoy today . great fun . emergency UNK ev...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>10</th>
      <td>5775</td>
      <td>8242</td>
      <td>rioting</td>
      <td>hertfordshire.</td>
      <td>But the government will not care. Police will ...</td>
      <td>1</td>
      <td>but the government will not care police will s...</td>
      <td>government care . police stop rioting eventual...</td>
      <td>But the government will not care. Police will ...</td>
      <td>but the government will not care police will s...</td>
      <td>government care . police stop rioting eventual...</td>
      <td>but the government will not UNK police will st...</td>
      <td>but the government will not UNK police will st...</td>
      <td>government UNK . police stop rioting UNK UNK ....</td>
      <td>0</td>
    </tr>
    <tr>
      <th>11</th>
      <td>6850</td>
      <td>9818</td>
      <td>trauma</td>
      <td>NaN</td>
      <td>@crazyindapeg @VETS78734 completely understand...</td>
      <td>0</td>
      <td>crazyindapeg vets78734 completely understandab...</td>
      <td>@crazyindapeg @vets78734 completely understand...</td>
      <td>@crazyindapeg @VETS78734 completely understand...</td>
      <td>crazyindapeg vets78734 completely understandab...</td>
      <td>@crazyindapeg @vets78734 completely understand...</td>
      <td>UNK UNK UNK UNK UNK the trauma UNK</td>
      <td>UNK UNK UNK UNK UNK the trauma UNK</td>
      <td>UNK UNK UNK UNK UNK trauma # UNK</td>
      <td>0</td>
    </tr>
    <tr>
      <th>12</th>
      <td>7241</td>
      <td>10369</td>
      <td>weapons</td>
      <td>NaN</td>
      <td>#bigbrother #ch4 The X-37b's big brother revea...</td>
      <td>0</td>
      <td>bigbrother ch4 the x 37b s big brother reveale...</td>
      <td># bigbrother # ch4 x-37b big brother reveal : ...</td>
      <td>#bigbrother #ch4 The X-37b's big brother revea...</td>
      <td>bigbrother ch4 the x 37b s big brother reveale...</td>
      <td># bigbrother # ch4 x-37b big brother reveal : ...</td>
      <td>UNK UNK the UNK big UNK UNK UNK bags UNK UNK t...</td>
      <td>UNK UNK the UNK UNK s big UNK UNK UNK bags 6 U...</td>
      <td># UNK # UNK UNK big UNK UNK : UNK bag $ UNK m ...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>13</th>
      <td>525</td>
      <td>759</td>
      <td>avalanche</td>
      <td>UK</td>
      <td>Musician Kalle Mattson Recreates 34 Classic Al...</td>
      <td>0</td>
      <td>musician kalle mattson recreates 34 classic al...</td>
      <td>musician kalle mattson recreate 34 classic alb...</td>
      <td>Musician Kalle Mattson Recreates 34 Classic Al...</td>
      <td>musician kalle mattson recreates 34 classic al...</td>
      <td>musician kalle mattson recreate 34 classic alb...</td>
      <td>UNK UNK UNK UNK UNK UNK album UNK in UNK music...</td>
      <td>UNK UNK UNK UNK UNK UNK album UNK in UNK music...</td>
      <td>UNK UNK UNK UNK UNK UNK album cover UNK music ...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>14</th>
      <td>5015</td>
      <td>7154</td>
      <td>mudslide</td>
      <td>Wales</td>
      <td>Hope Dorett's 'mudslide' cake wins?? #GBBO</td>
      <td>0</td>
      <td>hope dorett s mudslide cake wins gbbo</td>
      <td>hope dorett ' mudslide ' cake win ? ? # gbbo</td>
      <td>Hope Dorett's 'mudslide' cake wins?? #GBBO</td>
      <td>hope dorett s mudslide cake wins gbbo</td>
      <td>hope dorett ' mudslide ' cake win ?_? # gbbo</td>
      <td>hope UNK UNK cake UNK UNK</td>
      <td>hope UNK s mudslide cake UNK UNK</td>
      <td>hope UNK ' mudslide ' cake win ?_? # UNK</td>
      <td>0</td>
    </tr>
    <tr>
      <th>15</th>
      <td>3639</td>
      <td>5188</td>
      <td>fatalities</td>
      <td>NaN</td>
      <td>Mortal Kombat X: All Fatalities On Meat Predat...</td>
      <td>0</td>
      <td>mortal kombat x all fatalities on meat predator</td>
      <td>mortal kombat x : fatality meat predator . \n ...</td>
      <td>Mortal Kombat X: All Fatalities On Meat Predat...</td>
      <td>mortal kombat x all fatalities on meat predator</td>
      <td>mortal kombat x : fatality meat predator . htt...</td>
      <td>UNK UNK UNK all fatalities on UNK UNK UNK</td>
      <td>UNK UNK UNK all fatalities on UNK UNK</td>
      <td>UNK UNK UNK : fatality UNK UNK . UNK</td>
      <td>0</td>
    </tr>
    <tr>
      <th>16</th>
      <td>4264</td>
      <td>6058</td>
      <td>heat%20wave</td>
      <td>State College, PA</td>
      <td>Must Read Forecast! Longest Streak of Triple-D...</td>
      <td>1</td>
      <td>must read forecast longest streak of triple di...</td>
      <td>read forecast ! long streak triple - digit hea...</td>
      <td>Must Read Forecast! Longest Streak of Triple-D...</td>
      <td>must read forecast longest streak of triple di...</td>
      <td>read forecast ! long streak triple - digit hea...</td>
      <td>must read UNK UNK UNK of UNK heat since 2013 w...</td>
      <td>must UNK UNK UNK UNK of UNK UNK heat since 201...</td>
      <td>read UNK ! long UNK UNK - UNK heat 2013 happen...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>17</th>
      <td>3218</td>
      <td>4617</td>
      <td>emergency%20services</td>
      <td>Henderson, Nevada</td>
      <td>Apply now to work for Dignity Health as #RN #E...</td>
      <td>0</td>
      <td>apply now to work for dignity health as rn eme...</td>
      <td>apply work dignity health # rn # emergency ser...</td>
      <td>Apply now to work for Dignity Health as #RN #E...</td>
      <td>apply now to work for dignity health as rn eme...</td>
      <td>apply work dignity health # rn # emergency ser...</td>
      <td>UNK now to work for UNK UNK as UNK UNK service...</td>
      <td>UNK now to work for UNK UNK as UNK emergency s...</td>
      <td>UNK work UNK health # UNK # emergency service ...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>18</th>
      <td>2227</td>
      <td>3185</td>
      <td>deluge</td>
      <td>NaN</td>
      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>
      <td>0</td>
      <td>the f amp ing things i do for gishwhes just go...</td>
      <td>f$&amp;amp;@ing thing # gishwhe get soak deluge go...</td>
      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>
      <td>the f amp ing things i do for gishwhes just go...</td>
      <td>f$&amp;amp;@ing thing # gishwhe get soak deluge go...</td>
      <td>the UNK things i do for UNK just got UNK in a ...</td>
      <td>the UNK amp UNK things i do for UNK just got U...</td>
      <td>UNK thing # UNK get UNK deluge go UNK UNK . UN...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>19</th>
      <td>1163</td>
      <td>1675</td>
      <td>bridge%20collapse</td>
      <td>NaN</td>
      <td>Sioux City Fire Officials Believe Bridge Colla...</td>
      <td>1</td>
      <td>sioux city fire officials believe bridge colla...</td>
      <td>sioux city fire official believe bridge collap...</td>
      <td>Sioux City Fire Officials Believe Bridge Colla...</td>
      <td>sioux city fire officials believe bridge colla...</td>
      <td>sioux city fire official believe bridge collap...</td>
      <td>UNK city fire officials believe bridge collaps...</td>
      <td>UNK city fire officials believe bridge collaps...</td>
      <td>UNK city fire official believe bridge collapse...</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Seems to have worked!</p>
<p>Now let's find out the accuracy and F1 score of our Word2Vec model using the unprocessed tweet data.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">valid</span><span class="p">[</span><span class="s1">'target'</span><span class="p">],</span> <span class="n">valid</span><span class="p">[</span><span class="s1">'prediction'</span><span class="p">])</span>
<span class="n">F1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">valid</span><span class="p">[</span><span class="s1">'target'</span><span class="p">],</span> <span class="n">valid</span><span class="p">[</span><span class="s1">'prediction'</span><span class="p">])</span>
<span class="n">accuracy</span><span class="p">,</span> <span class="n">F1</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(0.6407563025210085, 0.27388535031847133)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>64.08%</code> accuracy! That's about the same as the TF-IDF model. The F1 score on the other hand... yikes! <code>0.27</code>. Horrible!</p>
<p>Can we improve that with either of the preprocessed tweets?</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id='Word2Vec-with-"Simple"-Tweets'>
<a class="anchor" href="#Word2Vec-with-" simple aria-hidden="true"><span class="octicon octicon-link"></span></a>Word2Vec with "Simple" Tweets<a class="anchor-link" href="#Word2Vec-with-%22Simple%22-Tweets"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Once again, we clear out the predictions we've just made from <code>valid</code>.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">valid</span> <span class="o">=</span> <span class="n">valid</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">'prediction'</span><span class="p">])</span>
<span class="n">valid</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>index</th>
      <th>id</th>
      <th>keyword</th>
      <th>location</th>
      <th>text</th>
      <th>target</th>
      <th>text_simple</th>
      <th>text_spacy</th>
      <th>text_trigram</th>
      <th>text_trigram_simple</th>
      <th>text_trigram_spacy</th>
      <th>text_count_5</th>
      <th>text_simple_5</th>
      <th>text_spacy_5</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5830</td>
      <td>8329</td>
      <td>rubble</td>
      <td>West Africa</td>
      <td>#TNN: China's Stock Market Crash: Are There Ge...</td>
      <td>1</td>
      <td>tnn china s stock market crash are there gems ...</td>
      <td># tnn : china stock market crash : gem rubble ...</td>
      <td>#TNN: China's Stock Market Crash: Are There Ge...</td>
      <td>tnn china s stock market crash are there gems ...</td>
      <td># tnn : china stock market crash : gem rubble ...</td>
      <td>UNK china's stock market crash: are there gems...</td>
      <td>UNK china s stock market crash are there gems ...</td>
      <td># UNK : china stock market crash : gem rubble ...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2548</td>
      <td>3656</td>
      <td>destroy</td>
      <td>Honduras</td>
      <td>Black Ops 3 SEARCH AND DESTROY GAMEPLAY! (Hunt...</td>
      <td>0</td>
      <td>black ops 3 search and destroy gameplay hunted...</td>
      <td>black ops 3 search destroy gameplay ! ( hunt s...</td>
      <td>Black Ops 3 SEARCH AND DESTROY GAMEPLAY! (Hunt...</td>
      <td>black ops 3 search and destroy gameplay hunted...</td>
      <td>black ops 3 search destroy gameplay ! ( hunt s...</td>
      <td>black UNK 3 UNK and destroy UNK UNK UNK UNK UN...</td>
      <td>black UNK 3 UNK and destroy UNK UNK UNK UNK UNK</td>
      <td>black UNK 3 UNK destroy UNK ! ( UNK UNK UNK UN...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2644</td>
      <td>3796</td>
      <td>destruction</td>
      <td>NaN</td>
      <td>So you have a new weapon that can cause un-ima...</td>
      <td>1</td>
      <td>so you have a new weapon that can cause un ima...</td>
      <td>new weapon cause un - imaginable destruction .</td>
      <td>So you have a new weapon that can cause un-ima...</td>
      <td>so you have a new weapon that can cause un ima...</td>
      <td>new weapon cause un - imaginable destruction .</td>
      <td>so you have a new weapon that can cause UNK UNK</td>
      <td>so you have a new weapon that can cause UNK UN...</td>
      <td>new weapon cause UNK - UNK destruction .</td>
    </tr>
    <tr>
      <th>3</th>
      <td>6078</td>
      <td>8684</td>
      <td>sinkhole</td>
      <td>Haddonfield, NJ</td>
      <td>Georgia sinkhole closes road swallows whole po...</td>
      <td>1</td>
      <td>georgia sinkhole closes road swallows whole pond</td>
      <td>georgia sinkhole close road swallow pond http:...</td>
      <td>Georgia sinkhole closes road swallows whole po...</td>
      <td>georgia sinkhole closes road swallows whole pond</td>
      <td>georgia sinkhole close road swallow pond http:...</td>
      <td>UNK sinkhole UNK road UNK whole UNK UNK</td>
      <td>UNK sinkhole UNK road UNK whole UNK</td>
      <td>UNK sinkhole close road swallow UNK UNK</td>
    </tr>
    <tr>
      <th>4</th>
      <td>6531</td>
      <td>9342</td>
      <td>survived</td>
      <td>London</td>
      <td>Survived another tube strike with the last per...</td>
      <td>0</td>
      <td>survived another tube strike with the last per...</td>
      <td>survive tube strike person office reach home ....</td>
      <td>Survived another tube strike with the last per...</td>
      <td>survived another tube strike with the last per...</td>
      <td>survive tube strike person office reach home ....</td>
      <td>survived another UNK strike with the last pers...</td>
      <td>survived another UNK strike with the last pers...</td>
      <td>survive UNK strike person UNK UNK home . get w...</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Just like with TF-IDF (seeing a trend here?), the process this time around will be exactly the same as before. The only change we need to make is that we are indexing into the <code>text_simple_5</code> column in the <code>disaster_tweets</code> and <code>not_disaster_tweets</code> DataFrames.</p>
<p>Since the procedures are the same, let's skip to the metrics! (You can still expand the code below if you need a closer look.)</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Word2Vec</span><span class="p">(</span><span class="n">min_count</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">sample</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">workers</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="n">tweets</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="n">wd</span> <span class="k">for</span> <span class="n">wd</span> <span class="ow">in</span> <span class="n">tweet</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">' '</span><span class="p">)]</span>
    <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[</span><span class="s1">'text_simple_5'</span><span class="p">]</span>
<span class="p">]</span>

<span class="n">model</span><span class="o">.</span><span class="n">build_vocab</span><span class="p">(</span><span class="n">tweets</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">tweets</span><span class="p">,</span> <span class="n">total_examples</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">corpus_count</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">init_sims</span><span class="p">(</span><span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">valid</span><span class="p">[</span><span class="s1">'prediction'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">valid</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">'int'</span><span class="p">)</span>

<span class="k">for</span> <span class="n">valid_row</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">valid</span><span class="p">)):</span>
    <span class="n">valid_tweet</span> <span class="o">=</span> <span class="n">valid</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">valid_row</span><span class="p">,</span> <span class="s1">'text_simple_5'</span><span class="p">]</span>
    <span class="n">tokenized_valid_tweet</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'\s+'</span><span class="p">,</span> <span class="n">valid_tweet</span><span class="p">)</span> <span class="c1"># split on all whitespace characters</span>
    
    <span class="n">disaster_count</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">not_disaster_count</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="c1"># we can just reuse "disasters" and</span>
    <span class="c1"># "not_disasters" from earlier!</span>
    <span class="k">for</span> <span class="n">disaster_row</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">disasters</span><span class="p">)):</span>
        <span class="n">disaster_tweet</span> <span class="o">=</span> <span class="n">disasters</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">disaster_row</span><span class="p">,</span> <span class="s1">'text_simple_5'</span><span class="p">]</span>
        <span class="n">tokenized_disaster_tweet</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'\s+'</span><span class="p">,</span> <span class="n">disaster_tweet</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">model</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">n_similarity</span><span class="p">(</span><span class="n">tokenized_valid_tweet</span><span class="p">,</span> <span class="n">tokenized_disaster_tweet</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">0.7</span><span class="p">:</span>
            <span class="n">disaster_count</span> <span class="o">+=</span> <span class="mi">1</span>
        
    <span class="k">for</span> <span class="n">not_disaster_row</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">not_disasters</span><span class="p">)):</span>
        <span class="n">not_disaster_tweet</span> <span class="o">=</span> <span class="n">not_disasters</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">not_disaster_row</span><span class="p">,</span> <span class="s1">'text_simple_5'</span><span class="p">]</span>
        <span class="n">tokenized_not_disaster_tweet</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'\s+'</span><span class="p">,</span> <span class="n">not_disaster_tweet</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">model</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">n_similarity</span><span class="p">(</span><span class="n">tokenized_valid_tweet</span><span class="p">,</span> <span class="n">tokenized_not_disaster_tweet</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">0.7</span><span class="p">:</span>
            <span class="n">not_disaster_count</span> <span class="o">+=</span> <span class="mi">1</span>
            
    <span class="k">if</span> <span class="n">disaster_count</span> <span class="o">&gt;</span> <span class="n">not_disaster_count</span><span class="p">:</span>
        <span class="n">valid</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">valid_row</span><span class="p">,</span> <span class="s1">'prediction'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
        
<span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Runtime: </span><span class="si">{</span><span class="p">(</span><span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">)</span> <span class="o">/</span> <span class="mf">60.0</span><span class="si">}</span><span class="s1"> mins'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Runtime: 18.409112783273063 mins
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">valid</span><span class="p">[</span><span class="s1">'target'</span><span class="p">],</span> <span class="n">valid</span><span class="p">[</span><span class="s1">'prediction'</span><span class="p">])</span>
<span class="n">F1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">valid</span><span class="p">[</span><span class="s1">'target'</span><span class="p">],</span> <span class="n">valid</span><span class="p">[</span><span class="s1">'prediction'</span><span class="p">])</span>
<span class="n">accuracy</span><span class="p">,</span> <span class="n">F1</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(0.6859243697478992, 0.4503676470588235)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Quite an improvement! Our accuracy and F1 score went up to <code>68.59%</code> and <code>0.45</code>, respectively.</p>
<p>Now let's see how the SpaCy tweets perform in our Word2Vec model.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Word2Vec-with-SpaCy-Tweets">
<a class="anchor" href="#Word2Vec-with-SpaCy-Tweets" aria-hidden="true"><span class="octicon octicon-link"></span></a>Word2Vec with SpaCy Tweets<a class="anchor-link" href="#Word2Vec-with-SpaCy-Tweets"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Same process as before, let's clear the old predictions from <code>valid</code> and skip to the metrics!</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">valid</span> <span class="o">=</span> <span class="n">valid</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">'prediction'</span><span class="p">])</span>
<span class="n">valid</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>index</th>
      <th>id</th>
      <th>keyword</th>
      <th>location</th>
      <th>text</th>
      <th>target</th>
      <th>text_simple</th>
      <th>text_spacy</th>
      <th>text_trigram</th>
      <th>text_trigram_simple</th>
      <th>text_trigram_spacy</th>
      <th>text_count_5</th>
      <th>text_simple_5</th>
      <th>text_spacy_5</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5830</td>
      <td>8329</td>
      <td>rubble</td>
      <td>West Africa</td>
      <td>#TNN: China's Stock Market Crash: Are There Ge...</td>
      <td>1</td>
      <td>tnn china s stock market crash are there gems ...</td>
      <td># tnn : china stock market crash : gem rubble ...</td>
      <td>#TNN: China's Stock Market Crash: Are There Ge...</td>
      <td>tnn china s stock market crash are there gems ...</td>
      <td># tnn : china stock market crash : gem rubble ...</td>
      <td>UNK china's stock market crash: are there gems...</td>
      <td>UNK china s stock market crash are there gems ...</td>
      <td># UNK : china stock market crash : gem rubble ...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2548</td>
      <td>3656</td>
      <td>destroy</td>
      <td>Honduras</td>
      <td>Black Ops 3 SEARCH AND DESTROY GAMEPLAY! (Hunt...</td>
      <td>0</td>
      <td>black ops 3 search and destroy gameplay hunted...</td>
      <td>black ops 3 search destroy gameplay ! ( hunt s...</td>
      <td>Black Ops 3 SEARCH AND DESTROY GAMEPLAY! (Hunt...</td>
      <td>black ops 3 search and destroy gameplay hunted...</td>
      <td>black ops 3 search destroy gameplay ! ( hunt s...</td>
      <td>black UNK 3 UNK and destroy UNK UNK UNK UNK UN...</td>
      <td>black UNK 3 UNK and destroy UNK UNK UNK UNK UNK</td>
      <td>black UNK 3 UNK destroy UNK ! ( UNK UNK UNK UN...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2644</td>
      <td>3796</td>
      <td>destruction</td>
      <td>NaN</td>
      <td>So you have a new weapon that can cause un-ima...</td>
      <td>1</td>
      <td>so you have a new weapon that can cause un ima...</td>
      <td>new weapon cause un - imaginable destruction .</td>
      <td>So you have a new weapon that can cause un-ima...</td>
      <td>so you have a new weapon that can cause un ima...</td>
      <td>new weapon cause un - imaginable destruction .</td>
      <td>so you have a new weapon that can cause UNK UNK</td>
      <td>so you have a new weapon that can cause UNK UN...</td>
      <td>new weapon cause UNK - UNK destruction .</td>
    </tr>
    <tr>
      <th>3</th>
      <td>6078</td>
      <td>8684</td>
      <td>sinkhole</td>
      <td>Haddonfield, NJ</td>
      <td>Georgia sinkhole closes road swallows whole po...</td>
      <td>1</td>
      <td>georgia sinkhole closes road swallows whole pond</td>
      <td>georgia sinkhole close road swallow pond http:...</td>
      <td>Georgia sinkhole closes road swallows whole po...</td>
      <td>georgia sinkhole closes road swallows whole pond</td>
      <td>georgia sinkhole close road swallow pond http:...</td>
      <td>UNK sinkhole UNK road UNK whole UNK UNK</td>
      <td>UNK sinkhole UNK road UNK whole UNK</td>
      <td>UNK sinkhole close road swallow UNK UNK</td>
    </tr>
    <tr>
      <th>4</th>
      <td>6531</td>
      <td>9342</td>
      <td>survived</td>
      <td>London</td>
      <td>Survived another tube strike with the last per...</td>
      <td>0</td>
      <td>survived another tube strike with the last per...</td>
      <td>survive tube strike person office reach home ....</td>
      <td>Survived another tube strike with the last per...</td>
      <td>survived another tube strike with the last per...</td>
      <td>survive tube strike person office reach home ....</td>
      <td>survived another UNK strike with the last pers...</td>
      <td>survived another UNK strike with the last pers...</td>
      <td>survive UNK strike person UNK UNK home . get w...</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Word2Vec</span><span class="p">(</span><span class="n">min_count</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">sample</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">workers</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="n">tweets</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="n">wd</span> <span class="k">for</span> <span class="n">wd</span> <span class="ow">in</span> <span class="n">tweet</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">' '</span><span class="p">)]</span>
    <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[</span><span class="s1">'text_spacy_5'</span><span class="p">]</span>
<span class="p">]</span>

<span class="n">model</span><span class="o">.</span><span class="n">build_vocab</span><span class="p">(</span><span class="n">tweets</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">tweets</span><span class="p">,</span> <span class="n">total_examples</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">corpus_count</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">init_sims</span><span class="p">(</span><span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">valid</span><span class="p">[</span><span class="s1">'prediction'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">valid</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">'int'</span><span class="p">)</span>

<span class="k">for</span> <span class="n">valid_row</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">valid</span><span class="p">)):</span>
    <span class="n">valid_tweet</span> <span class="o">=</span> <span class="n">valid</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">valid_row</span><span class="p">,</span> <span class="s1">'text_spacy_5'</span><span class="p">]</span>
    <span class="n">tokenized_valid_tweet</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'\s+'</span><span class="p">,</span> <span class="n">valid_tweet</span><span class="p">)</span> <span class="c1"># split on all whitespace characters</span>
    
    <span class="n">disaster_count</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">not_disaster_count</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="c1"># we can just reuse "disasters" and</span>
    <span class="c1"># "not_disasters" from earlier!</span>
    <span class="k">for</span> <span class="n">disaster_row</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">disasters</span><span class="p">)):</span>
        <span class="n">disaster_tweet</span> <span class="o">=</span> <span class="n">disasters</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">disaster_row</span><span class="p">,</span> <span class="s1">'text_spacy_5'</span><span class="p">]</span>
        <span class="n">tokenized_disaster_tweet</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'\s+'</span><span class="p">,</span> <span class="n">disaster_tweet</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">model</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">n_similarity</span><span class="p">(</span><span class="n">tokenized_valid_tweet</span><span class="p">,</span> <span class="n">tokenized_disaster_tweet</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">0.7</span><span class="p">:</span>
            <span class="n">disaster_count</span> <span class="o">+=</span> <span class="mi">1</span>
        
    <span class="k">for</span> <span class="n">not_disaster_row</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">not_disasters</span><span class="p">)):</span>
        <span class="n">not_disaster_tweet</span> <span class="o">=</span> <span class="n">not_disasters</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">not_disaster_row</span><span class="p">,</span> <span class="s1">'text_spacy_5'</span><span class="p">]</span>
        <span class="n">tokenized_not_disaster_tweet</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'\s+'</span><span class="p">,</span> <span class="n">not_disaster_tweet</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">model</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">n_similarity</span><span class="p">(</span><span class="n">tokenized_valid_tweet</span><span class="p">,</span> <span class="n">tokenized_not_disaster_tweet</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">0.7</span><span class="p">:</span>
            <span class="n">not_disaster_count</span> <span class="o">+=</span> <span class="mi">1</span>
            
    <span class="k">if</span> <span class="n">disaster_count</span> <span class="o">&gt;</span> <span class="n">not_disaster_count</span><span class="p">:</span>
        <span class="n">valid</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">valid_row</span><span class="p">,</span> <span class="s1">'prediction'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
        
<span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Runtime: </span><span class="si">{</span><span class="p">(</span><span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">)</span> <span class="o">/</span> <span class="mf">60.0</span><span class="si">}</span><span class="s1"> mins'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Runtime: 16.03406145175298 mins
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">valid</span><span class="p">[</span><span class="s1">'target'</span><span class="p">],</span> <span class="n">valid</span><span class="p">[</span><span class="s1">'prediction'</span><span class="p">])</span>
<span class="n">F1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">valid</span><span class="p">[</span><span class="s1">'target'</span><span class="p">],</span> <span class="n">valid</span><span class="p">[</span><span class="s1">'prediction'</span><span class="p">])</span>
<span class="n">accuracy</span><span class="p">,</span> <span class="n">F1</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(0.6554621848739496, 0.3180873180873181)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>SpaCy again comes in the middle of our three tests with an accuracy of <code>65.55%</code> and F1 score of <code>0.32</code>.</p>
<p>Among the three datasets trained with a Word2Vec model, the "simple" tweets seem to have it again with an accuracy of <code>68.59%</code> and an F1 score of <code>0.45</code>.</p>
<p>Lastly, let's turn to transfer learning.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Transfer-Learning-with-fastai">
<a class="anchor" href="#Transfer-Learning-with-fastai" aria-hidden="true"><span class="octicon octicon-link"></span></a>Transfer Learning with fastai<a class="anchor-link" href="#Transfer-Learning-with-fastai"> </a>
</h1>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">fastai.text.all</span> <span class="kn">import</span> <span class="o">*</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Rather than create our own neural network from scratch that competes with something like Word2Vec, we can use transfer learning to quickly adapt our language data by using a model that's already been trained on a lot more data than just what we have.</p>
<p>From <a href="https://machinelearningmastery.com/transfer-learning-for-deep-learning/">Jason Brownlee</a>:</p>
<blockquote>
<p>Transfer learning is a machine learning method where a model developed for a task is reused as the starting point for a model on a second task.</p>
</blockquote>
<p>In order to perform transfer learning, we'll be using <a href="https://docs.fast.ai/">fastai</a>. Fastai is great because it really simplifies the training procedure, thereby making it super easy to perform an array of deep learning tasks.
We'll need two classes from fastai to conduct transfer learning with text: <code>language_model_learner</code> and <code>text_classifier_learner</code>. The former will allow us to shape the pretrained model with our own data to make a new language model, while the latter will allow us to create a classifier model for the tweets we have (the same task we've been doing above).</p>
<p>Let's start, per usual, with the unprocessed tweets.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Transfer-Learning-with-Unprocessed-Tweets">
<a class="anchor" href="#Transfer-Learning-with-Unprocessed-Tweets" aria-hidden="true"><span class="octicon octicon-link"></span></a>Transfer Learning with Unprocessed Tweets<a class="anchor-link" href="#Transfer-Learning-with-Unprocessed-Tweets"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Fastai uses PyTorch under the hood, which requires our data to be formatted in <a href="https://pytorch.org/docs/stable/data.html">a specific way</a>. In order to do this most efficiently, we can use fastai's <code>DataBlock</code> object and <code>.dataloaders()</code> method. With <code>DataBlock</code>, we can:</p>
<ol>
<li>Directly pull our columns from the dataframe that we'd like to train <em>and</em> test on.</li>
<li>Split the data however we'd like.</li>
<li><a href="https://docs.fast.ai/data.block#DataBlock">And more!</a></li>
</ol>
<p>Let's start by creating a <code>DataBlock</code> that we'll pass to <code>language_model_learner</code> to create a new language model tailored to our data.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls_lm</span> <span class="o">=</span> <span class="n">DataBlock</span><span class="p">(</span>
    <span class="n">blocks</span><span class="o">=</span><span class="p">(</span><span class="n">TextBlock</span><span class="o">.</span><span class="n">from_df</span><span class="p">(</span><span class="s1">'text'</span><span class="p">,</span> <span class="n">is_lm</span><span class="o">=</span><span class="kc">True</span><span class="p">)),</span>
    <span class="n">get_items</span><span class="o">=</span><span class="n">ColReader</span><span class="p">(</span><span class="s1">'text'</span><span class="p">),</span>
    <span class="n">splitter</span><span class="o">=</span><span class="n">RandomSplitter</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
<span class="p">)</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">bs</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">seq_len</span><span class="o">=</span><span class="mi">80</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Note that there is only one block in the <code>DataBlock</code> we just created: a <code>TextBlock</code>. All we need to create a language model is the text (we don't care about the categories yet), so we only need one block in the <code>DataBlock</code>. We also need to specify the parameter <code>is_lm=True</code> when creating the <code>TextBlock</code>, to specify that this is our language model.</p>
<p>Now we can use <code>.show_batch()</code> to take a look at our newly formatted data:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls_lm</span><span class="o">.</span><span class="n">show_batch</span><span class="p">(</span><span class="n">max_n</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>text_</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>xxbos xxmaj investigators shift focus to cause of fatal xxmaj waimate fire http : / / t.co / xxunk xxbos xxunk - old xxmaj baby xxmaj girl was xxmaj rescued by xxmaj xxunk after xxmaj she xxmaj floated xxup half a xxup mile xxmaj out to xxmaj sea ! # socialnews http : / / t.co / xxunk xxbos xxunk xxunk xxunk xxmaj joe ur so xxunk u should run 4 president xxmaj ur perfect ! the xxmaj american people</td>
      <td>xxmaj investigators shift focus to cause of fatal xxmaj waimate fire http : / / t.co / xxunk xxbos xxunk - old xxmaj baby xxmaj girl was xxmaj rescued by xxmaj xxunk after xxmaj she xxmaj floated xxup half a xxup mile xxmaj out to xxmaj sea ! # socialnews http : / / t.co / xxunk xxbos xxunk xxunk xxunk xxmaj joe ur so xxunk u should run 4 president xxmaj ur perfect ! the xxmaj american people love</td>
    </tr>
    <tr>
      <th>1</th>
      <td>in xxmaj xxunk http : / / t.co / xxunk xxbos xxunk \n xxmaj parents of xxmaj colorado theater shooting victim fear copycat massacre \n\n http : / / t.co / lvlh3w3awo \n  # xxmaj antioch \n\n http : / / t.co / viwxy1xdyk xxbos xxmaj xxunk : xxunk : 10th xxmaj december 2013 xxmaj green xxmaj xxunk in xxmaj xxunk for the xxmaj swiss xxmaj xxunk of xxmaj the xxmaj desolation … http : / / t.co / xxunk</td>
      <td>xxmaj xxunk http : / / t.co / xxunk xxbos xxunk \n xxmaj parents of xxmaj colorado theater shooting victim fear copycat massacre \n\n http : / / t.co / lvlh3w3awo \n  # xxmaj antioch \n\n http : / / t.co / viwxy1xdyk xxbos xxmaj xxunk : xxunk : 10th xxmaj december 2013 xxmaj green xxmaj xxunk in xxmaj xxunk for the xxmaj swiss xxmaj xxunk of xxmaj the xxmaj desolation … http : / / t.co / xxunk xxbos</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can now instantiate our <code>language_model_learner</code> using the <code>DataBlock</code> we just created and <code>AWD_LSTM</code> which is a pretrained model provided by fastai. You can learn more about <code>AWD_LSTM</code> <a href="https://arxiv.org/pdf/1708.02182.pdf">here</a>.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">language_model_learner</span><span class="p">(</span>
    <span class="n">dls_lm</span><span class="p">,</span> <span class="n">AWD_LSTM</span><span class="p">,</span> <span class="n">drop_mult</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
    <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">accuracy</span><span class="p">,</span> <span class="n">Perplexity</span><span class="p">()])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>All that's left to do is fit our language model!</p>
<p>You'll note that fastai also provides super clear, customizable output for each training cycle.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">2e-2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>perplexity</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>4.491828</td>
      <td>3.658581</td>
      <td>0.387017</td>
      <td>38.806240</td>
      <td>01:48</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mf">2e-3</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>perplexity</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>3.770010</td>
      <td>3.639670</td>
      <td>0.388401</td>
      <td>38.079266</td>
      <td>01:46</td>
    </tr>
    <tr>
      <td>1</td>
      <td>3.734939</td>
      <td>3.569396</td>
      <td>0.392728</td>
      <td>35.495167</td>
      <td>01:50</td>
    </tr>
    <tr>
      <td>2</td>
      <td>3.692173</td>
      <td>3.482843</td>
      <td>0.399855</td>
      <td>32.552151</td>
      <td>01:44</td>
    </tr>
    <tr>
      <td>3</td>
      <td>3.618958</td>
      <td>3.413075</td>
      <td>0.409730</td>
      <td>30.358452</td>
      <td>01:44</td>
    </tr>
    <tr>
      <td>4</td>
      <td>3.560955</td>
      <td>3.363452</td>
      <td>0.415191</td>
      <td>28.888756</td>
      <td>01:46</td>
    </tr>
    <tr>
      <td>5</td>
      <td>3.494952</td>
      <td>3.328071</td>
      <td>0.418787</td>
      <td>27.884504</td>
      <td>01:46</td>
    </tr>
    <tr>
      <td>6</td>
      <td>3.442179</td>
      <td>3.305729</td>
      <td>0.423154</td>
      <td>27.268423</td>
      <td>01:45</td>
    </tr>
    <tr>
      <td>7</td>
      <td>3.399147</td>
      <td>3.295249</td>
      <td>0.424829</td>
      <td>26.984131</td>
      <td>01:46</td>
    </tr>
    <tr>
      <td>8</td>
      <td>3.362297</td>
      <td>3.289747</td>
      <td>0.425076</td>
      <td>26.836067</td>
      <td>01:44</td>
    </tr>
    <tr>
      <td>9</td>
      <td>3.334519</td>
      <td>3.288971</td>
      <td>0.425076</td>
      <td>26.815262</td>
      <td>01:44</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The accuracy above represents the models ability to predict the next word in a sequence from our disaster tweets data. 42.51%! That's pretty dang good for something that took about the same time as our Word2Vec models.</p>
<p>But we're not after text prediction, we're after text classification. Let's turn to that now.</p>
<p>First, let's create a <code>DataBlock</code> that we'll pass to <code>text_classifier_learner</code>. Notice that now we're passing two blocks to the <code>blocks</code> parameter: <code>TextBlock</code> and <code>CategoryBlock</code>. We specify these with the <code>get_x</code> and <code>get_y</code> parameters. It is also important to note the new <code>TextBlock</code> parameter <code>vocab</code>. Without this, the language model fitting we did above will mean nothing!</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls_clas</span> <span class="o">=</span> <span class="n">DataBlock</span><span class="p">(</span>
    <span class="n">blocks</span><span class="o">=</span><span class="p">(</span><span class="n">TextBlock</span><span class="o">.</span><span class="n">from_df</span><span class="p">(</span><span class="s1">'text'</span><span class="p">,</span> <span class="n">vocab</span><span class="o">=</span><span class="n">dls_lm</span><span class="o">.</span><span class="n">vocab</span><span class="p">,</span> <span class="n">seq_len</span><span class="o">=</span><span class="mi">80</span><span class="p">),</span> <span class="n">CategoryBlock</span><span class="p">),</span>
    <span class="n">get_x</span><span class="o">=</span><span class="n">ColReader</span><span class="p">(</span><span class="s1">'text'</span><span class="p">),</span>
    <span class="n">get_y</span><span class="o">=</span><span class="n">ColReader</span><span class="p">(</span><span class="s1">'target'</span><span class="p">),</span>
    <span class="n">splitter</span><span class="o">=</span><span class="n">RandomSplitter</span><span class="p">()</span>
<span class="p">)</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">bs</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">seq_len</span><span class="o">=</span><span class="mi">80</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/opt/miniconda3/lib/python3.8/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Check to see that our data is how we want it.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls_clas</span><span class="o">.</span><span class="n">show_batch</span><span class="p">(</span><span class="n">max_n</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>category</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>xxbos . : . : . : . : . : . : . : . : . : . : . : . : . : . : . : . : . : . : . : . : . : xxup rt xxunk : # xxunk \n\n xxmaj indian xxmaj army xxunk _ http : / / t.co / xxunk g</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>xxbos xxup info xxup s. xxup xxunk : xxunk / 6 . xxup xxunk : xxup xxunk xxup xxunk . xxup exp xxup xxunk xxup xxunk . xxup xxunk 05 . xxup curfew xxup in xxup xxunk xxup until xxunk xxup xxunk xxup xxunk xxup foxtrot 5 &amp; &amp; xxup foxtrot 6 xxup xxunk . xxup xxunk : 10 . xxpad xxpad xxpad xxpad</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>xxbos xxup info xxup r. xxup curfew xxup in xxup xxunk xxup until xxunk xxup xxunk xxup xxunk xxup foxtrot 5 &amp; &amp; xxup foxtrot 6 xxup xxunk . xxup xxunk : xxunk / 5 . xxup exp xxup xxunk xxup xxunk . xxup xxunk 05 . xxup xxunk . xxup xxunk : 10 . xxup xxunk : xxunk . xxpad xxpad xxpad xxpad</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now it's time to create our text classifier model, again using transfer learning from the <code>AWD_LSTM</code> model provided by fastai. This time we want to see the accuracy and F1 score when testing on the validation set.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">text_classifier_learner</span><span class="p">(</span><span class="n">dls_clas</span><span class="p">,</span> <span class="n">AWD_LSTM</span><span class="p">,</span> <span class="n">drop_mult</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">accuracy</span><span class="p">,</span> <span class="n">F1Score</span><span class="p">()])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we can fit:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">2e-2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>f1_score</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.749260</td>
      <td>0.501972</td>
      <td>0.770039</td>
      <td>0.688612</td>
      <td>00:45</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And that's. It.</p>
<p>Crazy, right?! One last step that we need to take care of to inch our models accuracy up further is <a href="https://stats.stackexchange.com/questions/393168/what-does-it-mean-to-freeze-or-unfreeze-a-model">gradual unfreezing</a>. Unfreezing a few layers at a time seems to make a real different in NLP, so we'll do that here (in computer vision, the model will often be unfrozen all at once).</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">freeze_to</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">slice</span><span class="p">(</span><span class="mf">1e-2</span><span class="o">/</span><span class="p">(</span><span class="mf">2.6</span><span class="o">**</span><span class="mi">4</span><span class="p">),</span><span class="mf">1e-2</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>f1_score</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.651064</td>
      <td>0.493843</td>
      <td>0.783837</td>
      <td>0.728772</td>
      <td>00:56</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">freeze_to</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">slice</span><span class="p">(</span><span class="mf">5e-3</span><span class="o">/</span><span class="p">(</span><span class="mf">2.6</span><span class="o">**</span><span class="mi">4</span><span class="p">),</span><span class="mf">5e-3</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>f1_score</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.547001</td>
      <td>0.461932</td>
      <td>0.795007</td>
      <td>0.724868</td>
      <td>01:35</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">unfreeze</span><span class="p">()</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="nb">slice</span><span class="p">(</span><span class="mf">1e-3</span><span class="o">/</span><span class="p">(</span><span class="mf">2.6</span><span class="o">**</span><span class="mi">4</span><span class="p">),</span><span class="mf">1e-3</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>f1_score</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.495468</td>
      <td>0.445766</td>
      <td>0.800263</td>
      <td>0.731922</td>
      <td>02:13</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.473490</td>
      <td>0.442739</td>
      <td>0.808147</td>
      <td>0.749141</td>
      <td>02:15</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>After fully unfreezing and fitting our model, our accuracy is... <code>80.81%</code>! Over 11% better than our best Word2Vec! Impressive. Our F1 score of <code>0.749</code> also blows away our best Word2Vec F1 score of <code>0.450</code>. Impressive, indeed.</p>
<p>But how will transfer learning perform will the preprocessed tweets? Let's find out!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id='Transfer-Learning-with-"Simple"-Tweets'>
<a class="anchor" href="#Transfer-Learning-with-" simple aria-hidden="true"><span class="octicon octicon-link"></span></a>Transfer Learning with "Simple" Tweets<a class="anchor-link" href="#Transfer-Learning-with-%22Simple%22-Tweets"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In order to repeat the same process for transfer learning on the preprocessed tweets, we'll need to create a whole new language model for each set. This is done almost exactly in the same way as above. The two differences are:</p>
<ol>
<li>The column that your selecting from will change from <code>text</code> to <code>text_simple</code> or <code>text_spacy</code>.</li>
<li>The <code>get_x</code> parameter when creating the <code>DataBlock</code> for the <code>text_classifier_learner</code>, <code>dls_clas</code>, must <em>remain</em> <code>text</code>, no matter the name of the column in the DataFrame that you are using as the independent variable. <a href="https://forums.fast.ai/t/issue-with-textblock-from-df-dataloaders-only-accepting-one-column-name/77467">[1]</a>
</li>
</ol>
<p>Knowing this, let's skip to the fitting and metrics!</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls_lm</span> <span class="o">=</span> <span class="n">DataBlock</span><span class="p">(</span>
    <span class="n">blocks</span><span class="o">=</span><span class="p">(</span><span class="n">TextBlock</span><span class="o">.</span><span class="n">from_df</span><span class="p">(</span><span class="s1">'text_simple'</span><span class="p">,</span> <span class="n">is_lm</span><span class="o">=</span><span class="kc">True</span><span class="p">)),</span>
    <span class="n">get_items</span><span class="o">=</span><span class="n">ColReader</span><span class="p">(</span><span class="s1">'text_simple'</span><span class="p">),</span>
    <span class="n">splitter</span><span class="o">=</span><span class="n">RandomSplitter</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
<span class="p">)</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">bs</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">seq_len</span><span class="o">=</span><span class="mi">80</span><span class="p">)</span>

<span class="n">learn</span> <span class="o">=</span> <span class="n">language_model_learner</span><span class="p">(</span><span class="n">dls_lm</span><span class="p">,</span> <span class="n">AWD_LSTM</span><span class="p">,</span> <span class="n">drop_mult</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">accuracy</span><span class="p">,</span> <span class="n">Perplexity</span><span class="p">()])</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">2e-2</span><span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mf">2e-3</span><span class="p">)</span>

<span class="n">dls_clas</span> <span class="o">=</span> <span class="n">DataBlock</span><span class="p">(</span>
    <span class="n">blocks</span><span class="o">=</span><span class="p">(</span><span class="n">TextBlock</span><span class="o">.</span><span class="n">from_df</span><span class="p">(</span><span class="s1">'text_simple'</span><span class="p">,</span> <span class="n">vocab</span><span class="o">=</span><span class="n">dls_lm</span><span class="o">.</span><span class="n">vocab</span><span class="p">,</span> <span class="n">seq_len</span><span class="o">=</span><span class="mi">80</span><span class="p">),</span> <span class="n">CategoryBlock</span><span class="p">),</span>
    <span class="n">get_x</span><span class="o">=</span><span class="n">ColReader</span><span class="p">(</span><span class="s1">'text'</span><span class="p">),</span>
    <span class="n">get_y</span><span class="o">=</span><span class="n">ColReader</span><span class="p">(</span><span class="s1">'target'</span><span class="p">),</span>
    <span class="n">splitter</span><span class="o">=</span><span class="n">RandomSplitter</span><span class="p">()</span>
<span class="p">)</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">bs</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">seq_len</span><span class="o">=</span><span class="mi">80</span><span class="p">)</span>

<span class="n">learn</span> <span class="o">=</span> <span class="n">text_classifier_learner</span><span class="p">(</span><span class="n">dls_clas</span><span class="p">,</span> <span class="n">AWD_LSTM</span><span class="p">,</span> <span class="n">drop_mult</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">accuracy</span><span class="p">,</span> <span class="n">F1Score</span><span class="p">()])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>perplexity</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>6.004099</td>
      <td>5.214499</td>
      <td>0.192453</td>
      <td>183.919571</td>
      <td>01:07</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>perplexity</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>5.320492</td>
      <td>5.192002</td>
      <td>0.193625</td>
      <td>179.828171</td>
      <td>01:04</td>
    </tr>
    <tr>
      <td>1</td>
      <td>5.292618</td>
      <td>5.105195</td>
      <td>0.207221</td>
      <td>164.876144</td>
      <td>01:02</td>
    </tr>
    <tr>
      <td>2</td>
      <td>5.235547</td>
      <td>4.998462</td>
      <td>0.215516</td>
      <td>148.185104</td>
      <td>01:03</td>
    </tr>
    <tr>
      <td>3</td>
      <td>5.170645</td>
      <td>4.908301</td>
      <td>0.223763</td>
      <td>135.409149</td>
      <td>01:04</td>
    </tr>
    <tr>
      <td>4</td>
      <td>5.104895</td>
      <td>4.837043</td>
      <td>0.233116</td>
      <td>126.095909</td>
      <td>01:03</td>
    </tr>
    <tr>
      <td>5</td>
      <td>5.043310</td>
      <td>4.787548</td>
      <td>0.240815</td>
      <td>120.006699</td>
      <td>01:05</td>
    </tr>
    <tr>
      <td>6</td>
      <td>4.986475</td>
      <td>4.756124</td>
      <td>0.245714</td>
      <td>116.294296</td>
      <td>01:03</td>
    </tr>
    <tr>
      <td>7</td>
      <td>4.937574</td>
      <td>4.738180</td>
      <td>0.249441</td>
      <td>114.226082</td>
      <td>01:02</td>
    </tr>
    <tr>
      <td>8</td>
      <td>4.897347</td>
      <td>4.731004</td>
      <td>0.250125</td>
      <td>113.409393</td>
      <td>01:03</td>
    </tr>
    <tr>
      <td>9</td>
      <td>4.865251</td>
      <td>4.729824</td>
      <td>0.250174</td>
      <td>113.275574</td>
      <td>01:04</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/opt/miniconda3/lib/python3.8/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">2e-2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>f1_score</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.727587</td>
      <td>0.518452</td>
      <td>0.754928</td>
      <td>0.699436</td>
      <td>00:31</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now gradually unfreeze:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">freeze_to</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">slice</span><span class="p">(</span><span class="mf">1e-2</span><span class="o">/</span><span class="p">(</span><span class="mf">2.6</span><span class="o">**</span><span class="mi">4</span><span class="p">),</span><span class="mf">1e-2</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>f1_score</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.614805</td>
      <td>0.490569</td>
      <td>0.770039</td>
      <td>0.709302</td>
      <td>00:38</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">freeze_to</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">slice</span><span class="p">(</span><span class="mf">5e-3</span><span class="o">/</span><span class="p">(</span><span class="mf">2.6</span><span class="o">**</span><span class="mi">4</span><span class="p">),</span><span class="mf">5e-3</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>f1_score</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.532009</td>
      <td>0.480033</td>
      <td>0.770696</td>
      <td>0.727557</td>
      <td>01:02</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">unfreeze</span><span class="p">()</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="nb">slice</span><span class="p">(</span><span class="mf">1e-3</span><span class="o">/</span><span class="p">(</span><span class="mf">2.6</span><span class="o">**</span><span class="mi">4</span><span class="p">),</span><span class="mf">1e-3</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>f1_score</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.481711</td>
      <td>0.469448</td>
      <td>0.778581</td>
      <td>0.730184</td>
      <td>01:26</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.458739</td>
      <td>0.468709</td>
      <td>0.785808</td>
      <td>0.733224</td>
      <td>01:25</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Accuracy: <code>78.58%</code>. F1 score: <code>0.733</code>.</p>
<p>Still great results, but not better than the unprocessed tweets. This is the opposite of what happened with TF-IDF and Word2Vec.</p>
<p>Let's see how the SpaCy tweets perform:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Transfer-Learning-with-SpaCy-Tweets">
<a class="anchor" href="#Transfer-Learning-with-SpaCy-Tweets" aria-hidden="true"><span class="octicon octicon-link"></span></a>Transfer Learning with SpaCy Tweets<a class="anchor-link" href="#Transfer-Learning-with-SpaCy-Tweets"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's do the same thing with our tweets preprocessed with SpaCy:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls_lm</span> <span class="o">=</span> <span class="n">DataBlock</span><span class="p">(</span>
    <span class="n">blocks</span><span class="o">=</span><span class="p">(</span><span class="n">TextBlock</span><span class="o">.</span><span class="n">from_df</span><span class="p">(</span><span class="s1">'text_spacy'</span><span class="p">,</span> <span class="n">is_lm</span><span class="o">=</span><span class="kc">True</span><span class="p">)),</span>
    <span class="n">get_items</span><span class="o">=</span><span class="n">ColReader</span><span class="p">(</span><span class="s1">'text_spacy'</span><span class="p">),</span>
    <span class="n">splitter</span><span class="o">=</span><span class="n">RandomSplitter</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
<span class="p">)</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">bs</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">seq_len</span><span class="o">=</span><span class="mi">80</span><span class="p">)</span>

<span class="n">learn</span> <span class="o">=</span> <span class="n">language_model_learner</span><span class="p">(</span><span class="n">dls_lm</span><span class="p">,</span> <span class="n">AWD_LSTM</span><span class="p">,</span> <span class="n">drop_mult</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">accuracy</span><span class="p">,</span> <span class="n">Perplexity</span><span class="p">()])</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">2e-2</span><span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mf">2e-3</span><span class="p">)</span>

<span class="n">dls_clas</span> <span class="o">=</span> <span class="n">DataBlock</span><span class="p">(</span>
    <span class="n">blocks</span><span class="o">=</span><span class="p">(</span><span class="n">TextBlock</span><span class="o">.</span><span class="n">from_df</span><span class="p">(</span><span class="s1">'text_spacy'</span><span class="p">,</span> <span class="n">vocab</span><span class="o">=</span><span class="n">dls_lm</span><span class="o">.</span><span class="n">vocab</span><span class="p">,</span> <span class="n">seq_len</span><span class="o">=</span><span class="mi">80</span><span class="p">),</span> <span class="n">CategoryBlock</span><span class="p">),</span>
    <span class="n">get_x</span><span class="o">=</span><span class="n">ColReader</span><span class="p">(</span><span class="s1">'text'</span><span class="p">),</span>
    <span class="n">get_y</span><span class="o">=</span><span class="n">ColReader</span><span class="p">(</span><span class="s1">'target'</span><span class="p">),</span>
    <span class="n">splitter</span><span class="o">=</span><span class="n">RandomSplitter</span><span class="p">()</span>
<span class="p">)</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">bs</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">seq_len</span><span class="o">=</span><span class="mi">80</span><span class="p">)</span>

<span class="n">learn</span> <span class="o">=</span> <span class="n">text_classifier_learner</span><span class="p">(</span><span class="n">dls_clas</span><span class="p">,</span> <span class="n">AWD_LSTM</span><span class="p">,</span> <span class="n">drop_mult</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">accuracy</span><span class="p">,</span> <span class="n">F1Score</span><span class="p">()])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>perplexity</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>5.706690</td>
      <td>4.312386</td>
      <td>0.360170</td>
      <td>74.618286</td>
      <td>01:07</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>perplexity</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>4.617074</td>
      <td>4.272776</td>
      <td>0.362547</td>
      <td>71.720467</td>
      <td>01:07</td>
    </tr>
    <tr>
      <td>1</td>
      <td>4.551154</td>
      <td>4.126544</td>
      <td>0.394834</td>
      <td>61.963436</td>
      <td>01:06</td>
    </tr>
    <tr>
      <td>2</td>
      <td>4.463481</td>
      <td>3.999427</td>
      <td>0.411593</td>
      <td>54.566891</td>
      <td>01:06</td>
    </tr>
    <tr>
      <td>3</td>
      <td>4.374925</td>
      <td>3.913188</td>
      <td>0.417397</td>
      <td>50.058308</td>
      <td>01:06</td>
    </tr>
    <tr>
      <td>4</td>
      <td>4.295952</td>
      <td>3.850333</td>
      <td>0.422705</td>
      <td>47.008724</td>
      <td>01:08</td>
    </tr>
    <tr>
      <td>5</td>
      <td>4.222636</td>
      <td>3.804458</td>
      <td>0.428141</td>
      <td>44.900890</td>
      <td>01:07</td>
    </tr>
    <tr>
      <td>6</td>
      <td>4.170039</td>
      <td>3.776617</td>
      <td>0.429490</td>
      <td>43.668045</td>
      <td>01:10</td>
    </tr>
    <tr>
      <td>7</td>
      <td>4.108244</td>
      <td>3.760522</td>
      <td>0.431906</td>
      <td>42.970837</td>
      <td>01:08</td>
    </tr>
    <tr>
      <td>8</td>
      <td>4.065337</td>
      <td>3.753966</td>
      <td>0.433294</td>
      <td>42.690048</td>
      <td>01:09</td>
    </tr>
    <tr>
      <td>9</td>
      <td>4.032233</td>
      <td>3.752884</td>
      <td>0.433529</td>
      <td>42.643887</td>
      <td>01:05</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/opt/miniconda3/lib/python3.8/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Fit the text classifier:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">2e-2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>f1_score</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.806559</td>
      <td>0.531039</td>
      <td>0.754928</td>
      <td>0.687343</td>
      <td>00:34</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Gradually unfreeze the model:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">freeze_to</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">slice</span><span class="p">(</span><span class="mf">1e-2</span><span class="o">/</span><span class="p">(</span><span class="mf">2.6</span><span class="o">**</span><span class="mi">4</span><span class="p">),</span><span class="mf">1e-2</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>f1_score</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.673772</td>
      <td>0.504315</td>
      <td>0.764126</td>
      <td>0.670944</td>
      <td>00:40</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">freeze_to</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">slice</span><span class="p">(</span><span class="mf">5e-3</span><span class="o">/</span><span class="p">(</span><span class="mf">2.6</span><span class="o">**</span><span class="mi">4</span><span class="p">),</span><span class="mf">5e-3</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>f1_score</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.589388</td>
      <td>0.492628</td>
      <td>0.770039</td>
      <td>0.694056</td>
      <td>01:05</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">unfreeze</span><span class="p">()</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="nb">slice</span><span class="p">(</span><span class="mf">1e-3</span><span class="o">/</span><span class="p">(</span><span class="mf">2.6</span><span class="o">**</span><span class="mi">4</span><span class="p">),</span><span class="mf">1e-3</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>f1_score</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.551138</td>
      <td>0.473456</td>
      <td>0.773982</td>
      <td>0.707980</td>
      <td>01:32</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.532972</td>
      <td>0.469976</td>
      <td>0.781866</td>
      <td>0.713299</td>
      <td>01:32</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Accuracy: <code>78.19%</code>. F1 score: <code>0.713</code>.</p>
<p>Whoa! These are the lowest of the three of our transfer learning models. How unexpected.</p>
<p>So between the three datasets used in transfer learning, the unprocessed dataset seemed to perform the best! Unexpected, indeed.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Conclusion">
<a class="anchor" href="#Conclusion" aria-hidden="true"><span class="octicon octicon-link"></span></a>Conclusion<a class="anchor-link" href="#Conclusion"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now that we've gone through each model: TF-IDF, Word2Vec, and transfer learning, it's time to compare the results:</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>Dataset</th>
<th>Accuracy</th>
<th>F1 Score</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>TF-IDF</strong></td>
<td>Unprocessed</td>
<td>62.08%</td>
<td>0.484</td>
</tr>
<tr>
<td>''</td>
<td>"Simple"</td>
<td>67.44%</td>
<td>0.556</td>
</tr>
<tr>
<td>''</td>
<td>SpaCy</td>
<td>65.60%</td>
<td>0.499</td>
</tr>
<tr>
<td><strong>Word2Vec</strong></td>
<td>Unprocessed</td>
<td>64.08%</td>
<td>0.274</td>
</tr>
<tr>
<td>''</td>
<td>"Simple"</td>
<td>68.59%</td>
<td>0.450</td>
</tr>
<tr>
<td>''</td>
<td>SpaCy</td>
<td>65.55%</td>
<td>0.318</td>
</tr>
<tr>
<td><strong>Transfer Learning</strong></td>
<td><strong>Unprocessed</strong></td>
<td><strong>80.81%</strong></td>
<td><strong>0.749</strong></td>
</tr>
<tr>
<td>''</td>
<td>"Simple"</td>
<td>78.58%</td>
<td>0.733</td>
</tr>
<tr>
<td>''</td>
<td>SpaCy</td>
<td>78.19%</td>
<td>0.713</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And the winner is, unsurprisingly, transfer learning! What is surprising, however, is that of the three datasets that we used for transfer learning, the unprocessed dataset yielded the best results. This provides strong support for transfer learning, as it is able to extract nuances in natural language as opposed to augemented, unnatural language.</p>
<p>If you're interesed in getting more involved with transfer learning, I strongly recommend Jeremy Howard and Rachel Thomas' course <a href="https://youtu.be/_QUEXsHfsA0">Deep Learning for Coders</a>. At the time of writing, this is an excellent resource for getting a really good, modern grasp of deep learning, provided you've got some basic Python programming experience. And it's all free!</p>
<p>With that, I'll leave the reader to experiment further with text classification and langauge modeling.</p>
<p>Questions I'm now asking myself:</p>
<ul>
<li>What other preprocessing methods or data augmentations techniques could we have used?</li>
<li>What's a transformer?</li>
<li>How does BERT work?</li>
<li>Where else can we apply text classification to somehow learn something meaningful?</li>
</ul>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="davbyron/blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/blog/tf-idf/word2vec/neural%20networks/text%20classification/natural%20language%20processing/2020/10/31/Text-Classification-Comparison.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>A blog dedicated to learning while educating about natural language processing and computational linguistics</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/davbyron" title="davbyron"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#github"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
